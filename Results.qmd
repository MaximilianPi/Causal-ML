---
title: "Results"
format: 
  docx:
    toc: true
    number-sections: true
    keep-md: true
    fig-format: pdf
crossref:
  fig-title: '**Figure**'
  fig-labels: arabic
  tbl-title: '**Table**'
  tbl-labels: arabic
  title-delim: ":"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = "cairo_pdf")
knitr::opts_chunk$set(fig.path="figures/", echo = FALSE)
```




```{r}
#| echo: false
#| message: false
library(ggplot2)
library(ggbreak)
library(tidyverse)
library(igraph)
library(Cairo)
source("utils.R")

```

## Results

### Proof of concept

```{r}
#| echo: false
#| message: false

files =        c("collinearity_0.5.RDS", 
                 "collinearity_0.90.RDS", 
                 "collinearity_0.99.RDS", 
                 "effects.RDS", 
                 "no_effects.RDS", 
                 "confounder_unequal.RDS", 
                 "confounder.RDS")

Results = 
  lapply(files, function(f) {
    confounder = readRDS(paste0("results/",f))
    Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:length(confounder), function(i) confounder[[i]][[j]][[1]] ), along = 0L), 2, mean))))
    colnames(Result) = LETTERS[1:5]
    rownames(Result) = c("LM", "RF", "BRT", "NN", "Dropout", "l1", "l2", "l1l2")
    return(Result)
  })
names(Results) = unlist(strsplit(files, ".RDS", TRUE))


Results_rmse = 
  lapply(files, function(f) {
    confounder = readRDS(paste0("results/",f))
    Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:length(confounder), function(i) confounder[[i]][[j]][[2]] ), along = 0L), 2, mean))))
    colnames(Result) = "RMSE"
    rownames(Result) = c("LM", "RF", "BRT", "NN", "Dropout","l1", "l2", "l1l2")
    return(Result)
  })
names(Results_rmse) = unlist(strsplit(files, ".RDS", TRUE))

RMSEs = round(do.call(cbind, Results_rmse), 3)
colnames(RMSEs) = unlist(strsplit(files, ".RDS", TRUE))

Results_sd = 
  lapply(files, function(f) {
    confounder = readRDS(paste0("results/",f))
    Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:length(confounder), function(i) confounder[[i]][[j]][[1]] ), along = 0L), 2, sd))))
    colnames(Result) = LETTERS[1:5]
    rownames(Result) = c("LM", "RF", "BRT", "NN","Dropout", "l1", "l2", "l1l2")
    return(Result)
  })
names(Results_sd) = unlist(strsplit(files, ".RDS", TRUE))



```

```{r}
#| label: fig-Fig_2
#| fig-format: pdf
#| fig-width: 12
#| fig-height: 7
#| echo: false
#| message: false
#| fig-cap: "Bias on effect estimates for different ML algorithms in three different simulated causal simulations (a and b). Sample sizes are so large that stochastic effects can be excluded (1000 observations and 500 repetitions). Effects of the ML models were inferred using average conditional effects. Row a) shows results for simulations with uncorrelated predictors with effect sizes ($\\beta_1$=1.0,  $\\beta_2$=0.0, and $\\beta_3$=1.0). Row b) shows the results for simulations with X~1~ and X~2~ being strongly correlated (Pearson correlation factor = 0.9) but only X~1~ affects y."

parser = function(true, bias, pos = 1) {
  if(pos == 1) { 
    yp = 1.25
    xp = 0.15
  }
  if(pos == 3) {
    yp = 1.63
    xp = -0.05
  }
  if(pos == 2) {
    yp = 0.37
    xp = -0.05
  }
  
  bb = round(bias, 2)
  if(bb > 0) { 
    symb = "+" 
    if(abs(bb) > 0.001) text(x = xp + 0.280, y = yp+0.01, pos = 4, symb, cex = 1.3, col = "#e60000", font = 2)
  } else { 
    symb = "-"
      if(abs(bb) > 0.001) text(x = xp + 0.29, y = yp, pos = 4, symb, cex = 1.3, col = "#e60000", font = 2)
    }
  bb = abs(bb)
   text(x = xp, y = yp, pos = 4,label = format(true, nsmall = 2), cex = 1.3)

  if(bb> 0.001) text(x = xp+ 0.35, y = yp, pos = 4, label = format(bb, nsmall = 2), cex = 1.3, col = "#e60000", font = 1)
}



sc = c("effects", "collinearity_0.90")

#cairo_pdf("plots/Fig_2.pdf", width = 12, height = 7)

par(mfcol = c(2,6), mar = c(5,0.5, 2, 1.4), oma = c(1, 2, 2, 1))
labs =  c("LM","RF",  "BRT", "NN","Dropout", "l1", "l2", "Elastic-net")
cex_fac = 1.3
minArrow = function(x) sapply(x, function(xx) max(c(0.1, xx)))

true_effs = matrix(c(
  1, 0.0, 1,
  1, 0.0, 1
), 2, 3, byrow = TRUE)

vertex_col_p = "#86A3B8"
vertex_col_y = "#E8D2A6"
vertex_col_frame = "#181823"
vertex_frame_width = 2.0

# A simulation

g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"),  
            directed=TRUE ) 
layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE)
eqarrowPlot(g1, matrix(c(1,1,
                         0,1,
                         0,0,
                         0,2), nrow = 4L, 2L, byrow = TRUE) ,
            cols = c(addA(rep(vertex_col_p, 1), 1.0), 
                     vertex_col_y, 
                     addA(rep(vertex_col_p, 1), 1.0),
                     addA(rep(vertex_col_p, 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0)),
            edge.width=c(1.00, 0.1, 1.0)*cex_fac,
            edge.label = rep("",3),
            edge.label.cex = 1.6,
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,
            vertex.frame.width = vertex_frame_width,
            edge.colors = rep("#B0A8B9", 3))
  text(letters[1], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
  text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.0, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)


# B simulation
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
            cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 2), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.1, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            edge.arrow.mode = c(rep(">", 3), "-"), 
            vertex.frame.width = vertex_frame_width,
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
text(letters[2], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.0, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)
points(x = 0, y = -0.55, col = "grey", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.55, label = "True effect", xpd = NA, pos = 4, cex = 1.4)
points(x = 0, y = -0.75, col = "#ffab02", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.75, label = "Correlation", xpd = NA, pos = 4, cex = 1.4)
for(i in c(1, 2, 3, 4, 8)) {
  counter = 1
  for(j in c(1, 2)) {

    tmp = Results[[sc[j]]]
    sd = Results_sd[[sc[j]]][i,]
    edges = round(tmp[i,], 5)
    bias = edges[c(1, 2, 5)] - true_effs[j,]
    g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"),  
                directed=TRUE ) 
    layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE)
    eqarrowPlot(g1, matrix(c(1,1,
                             0,1,
                             0,0,
                             0,2), nrow = 4L, 2L, byrow = TRUE) ,
                cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 1), 1.0)),
                edge.arrow.size=minArrow(abs(-true_effs[j,] - bias)),#abs(edges[c(1, 2, 5)]), 
                edge.width=abs(-true_effs[j,] - bias)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
                edge.label = rep("",3),
                vertex.frame.width = vertex_frame_width,
                vertex.frame.color=vertex_col_frame,
                vertex.label.color= vertex_col_frame,
                edge.label.cex = 1.4,
                edge.colors = ifelse(abs(bias) < 0.01, "#B0A8B9", "#DD5353"))
    parser(true_effs[j, 1], bias[1], pos = 1)
    parser(true_effs[j, 2], bias[2], pos = 2)
    parser(true_effs[j, 3], bias[3], pos = 3)
    text(labs[i], x = 0, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
    if(i == 1) {
      text(letters[counter], cex = 1.9, x = -2.2, y = 2.5, xpd = NA, font = 2)
      counter = counter + 1
    }

  }
  if(i == 3) {
    points(x = 0-1, y = -1.1*0.5, col = "#DD5353", xpd = NA, pch = 15, cex = 1.8)
    text(x = 0.1-1, y = -1.1*0.5, label = "Bias", xpd = NA, pos = 4, cex = 1.4)
  }
}

#dev.off()

```

### Data-poor simulation

```{r}
#| echo: false
#| message: false


effs_true = c(1.0, 0.0)
extract_B = function(RI, exponent = 1) {
  Bias = apply(abind::abind(lapply(1:length(RI), function(j) t(sapply(1:5, function(i) RI[[j]][[i]][1:2]  - effs_true))), along = 0L), 2:3, mean)**exponent
  Bias_1 = apply(Bias[,1, drop=FALSE], 1, mean)
  Bias_0 = apply(Bias[,2, drop=FALSE], 1, mean)
  return(cbind(Bias_1, Bias_0)) #, Bias_Inter_1, Bias_Inter_0))
}

extract_V= function(RI) {
  Var = apply(abind::abind(lapply(1:length(RI), function(j) t(sapply(1:5, function(i) RI[[j]][[i]][1:2] ))), along = 0L), 2:3, var)
  Var_1 = apply(Var[,1, drop=FALSE], 1, mean)
  Var_0 = apply(Var[,2, drop=FALSE], 1, mean)
  return(cbind(Var_1, Var_0))  #, Var_Inter_1, Var_Inter_0))
}

extract_results = function(path, N = "small", tuned = "pred") {

  inter_low = readRDS(path)
  bias_low = extract_B(inter_low, exponent = 1)
  var_low = extract_V(inter_low)
  mse = sapply(1:5, function(i) {mean(sapply(inter_low, function(r) r[[i]][3]))})
  

  return(list(bias = bias_low, var = var_low, mse = mse))
}

res_pred =  lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_MSE.RDS"), n, "pred"))
res_eff = lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_BIAS.RDS"), n, "eff"))

```

```{r}
#| label: fig-Fig_3
#| fig-format: pdf
#| fig-width: 10
#| fig-height: 7
#| echo: false
#| message: false
#| fig-cap: "Bias and variance of estimated effects in data-poor situations. N = 50, 100, and 600 observations of 100 weakly correlated predictors were simulated. True effects in the data generating model were $\\beta_1$=1.0, $\\beta_2$=0.0, and the other 98 effects were equally spaced between 0 and 1. Models were fitted to the simulated data (1000 replicates) with the optimal hyperparameters (except for LM, which doesn’t have hyperparameters). Hyperparameters were selected based on the minimum MSE of ($\\hat{\\beta}_1$) (green) or the prediction error (based on $\\hat{y}$  ) (red). Bias and variance were calculated for $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$. Effects $\\hat{\\beta}_i$ for $i=1,…,100$) were approximated using ACE."

#cairo_pdf("plots/Fig_3.pdf", width = 10, height = 7)

bias = res_pred[[1]]$bias[1, 1]
var = res_pred[[1]]$var[1, 1]
draw_stacked_bar = function(bias, var, xleft = 0.0, w = 0.15) {
  rect(xleft, 0, xleft+w, abs(bias), col = "#96c6ed" )
  rect(xleft, abs(bias), xleft+w, abs(bias)+var, col = "#e0acd5" )
}
methods2 = c("LM", "RF", "BRT", "NN", "Elastic-net")
methods2[-1] = paste0(methods2[-1], " tuned")
par(mfrow = c(3, 5), mar = c(1, 1, 1, 1)*0.5, oma = c(12, 4, 4, 4))
y_labels = c("N = 50", "N = 100", "N = 600")
for(j in 1:3) {
  for(i in 1:5) {
    plot(NULL, NULL, xlim = c(0, 1), ylim = c(0, 1), yaxt = "n", xaxt = "n", xaxs = "i", yaxs = "i", xlab = "", ylab = "")
    if( i > 1) {
      rect(0.5, 0, 1.0, 1.0, col = "#EDBD9660", border = NA)
      rect(0.0, 0, 0.5, 1.0, col = "#9BED9660", border = NA)

      draw_stacked_bar(xleft = 0.1, res_pred[[j]]$bias[i, 1], res_pred[[j]]$var[i, 1])
      draw_stacked_bar(xleft = 0.1+0.18, res_pred[[j]]$bias[i, 2], res_pred[[j]]$var[i, 2])
      draw_stacked_bar(xleft = 0.1+0.47, res_eff[[j]]$bias[i, 1], res_eff[[j]]$var[i, 1])
      draw_stacked_bar(xleft = 0.1+0.18+0.47, res_eff[[j]]$bias[i, 2], res_eff[[j]]$var[i, 2])
    } else {
      
      if( ((j %in% c(1, 2)) && (i == 1) )) {
        text(x = 0.5, y = 0.5, pos = 3, label = "NA", font = 2)
      } else {
        draw_stacked_bar(xleft = 0.325, res_pred[[j]]$bias[i, 1], res_pred[[j]]$var[i, 1])
        draw_stacked_bar(xleft = 0.325+0.18, res_pred[[j]]$bias[i, 2], res_pred[[j]]$var[i, 2])

        text(x = c(0.185, 0.185+0.18),y = -0.24, 
        labels = c("Bias+Variance \U03B2\U2081", "Bias+Variance \U03B2\U2082"), 
        srt = 45,
        xpd = NA, pos = 1)        
      }
      
    }
    if(j == 1) {
      rect(0, 1.0, 1.0, 1.15, xpd = NA, border = "black")
      text(0.5, y = 0.98, pos = 3, xpd = NA, label = methods2[i], cex = 1.3, font = 2)
    }
    if(i == 5) {
      rect(1, 0, 1.15, 1.0, xpd = NA, border = "black")
      text(y = 0.72, x = 1.01, pos = 4, xpd = NA, label = y_labels[j], cex = 1.3, font = 2, srt = -90)
    }
    if( (j == 3) && (i > 1) ){
      text(x = c(0.185, 0.185+0.18, c(0.185, 0.185+0.18)+0.47)-0.22,y = -0.24, 
           labels = c("Bias+Variance \U03B2\U2081", "Bias+Variance \U03B2\U2082", "Bias+Variance \U03B2\U2081", "Bias+Variance \U03B2\U2082"), 
           srt = 45,
           xpd = NA, pos = 1)
    }    
  }
}

points(pch = 15, x = rep(-1.0, 2), y = c(-0.7, -0.8), xpd = NA, col = c("#96c6ed","#e0acd5"), cex = 1.5)
text(x = rep(-1.0, 2)+0.01, y = c(-0.7, -0.8)-0.02, pos = 4, labels = c("Bias", "Variance"), xpd = NA)

points(pch = 15, x = rep(-0.2, 2), y = c(-0.7, -0.8), xpd = NA, col = c("#9BED96","#EDBD96"), cex = 1.5)
text(x = rep(-0.2, 2)+0.01, y = c(-0.7, -0.8)-0.02, pos = 4, labels = c("Tuned after MSE of predictions", "Tuned after MSE of \U03B2\U2081"), xpd = NA)

#dev.off()      

```

#### Hyper-parameter sensitivity analysis

```{r}
#| echo: false
#| message: false
library(xgboost)
library(ranger)
library(qgam)
library(mgcv)
library(mgcViz)
library(ggplot2)
library(tidyverse)
results = readRDS("results/hyper_parameter_aggregation_100.RDS")
data = do.call(rbind, lapply(results, function(r) r$data))
```

```{r}
#| label: fig-Fig_4
#| fig-format: pdf
#| fig-width: 9
#| fig-height: 10
#| echo: false
#| message: false
#| fig-cap: "Results of hyperparameter tuning for Neural Networks (NN), Boosted Regression Trees (BRT), Random Forests (RF), and Elastic Net (EN) for 100 observations with 100 predictors. The influence of the hyperparameters on effect ($\\hat{\\beta}_1$) (bias, variance, and MSE), and the predictions of the model, ($\\hat{y}$), (bias, variance, and MSE) were estimated by a multivariate generalized additive model (GAM). Categorical hyperparameters (activation function in NN) were estimated as fixed effects. The responses (bias, variance, MSE) were centered so that the categorical hyperparameters correspond to the intercepts. The variable importance of the hyperparameters was estimated by a random forest with the MSE of the effect $\\hat{\\beta}_1$ (first plot) or the prediction (second plot) as the response. Red dots correspond to the best predicted set of hyperparameters (based on a random forest), in the first plot for the minimum MSE of the effect for $\\hat{\\beta}_1$ and in the second plot for the minimum MSE of the predictions $\\hat{y}$."


# results = readRDS("results/hyper_parameter_aggregation_100.RDS")
# data = do.call(rbind, lapply(results, function(r) r$data))

labels = c("CELU",
           "ELU",
           "GELU",
           "Leaky ReLU",
           "ReLU",
           "SELU",
           "tanh",
           "batch size",
           "depth",
           "width",
           "alpha",
           "lambda",
           "eta",
           "max depth",
           "subsample",
           "max tree",
           "mtry",
           "min node size",
           "max depth",
           "regularization factor")
names(labels) = c("activationscelu",
                  "activationselu",
                  "activationsgelu",
                  "activationsleaky_relu",
                  "activationsrelu",
                  "activationsselu",
                  "activationstanh",
                  "sgd",
                  "depth", 
                  "width",
                  "alpha", 
                  "lambda",
                  "eta",
                  "max_depth",
                  "subsample",
                  "max_tree",
                  "mtry",
                  "min.node.size",
                  "max.depth",
                  "regularization.factor")

#cairo_pdf("plots/Fig_4.pdf", width = 9, height = 10)
tck = 0.015
mgp = 0.07 
eff_range = list(eff_range2 = c(-0.5, 0.5),eff_range1 = c(-0.04, 0.04))
vi_range = list(c(0, 0.04), c(0, 2.5))
cols = (c("#1C1C1BFF","#CC4A7EFF"))
plot_tuning(data = data, results = results, eff_range = eff_range, vi_range = vi_range, line_col = cols)
axis(3, at = scales::rescale(c(-0.25, 0.0, 0.25), to = c(0.02, 0.28), from = eff_range[[1]]), labels = c(-0.25, 0.0, 0.25), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(-0.02, 0.0, 0.02), to = c(0.02, 0.28), from = eff_range[[2]])+0.5, labels = c(-0.02, 0.0, 0.02), tck = tck, mgp = c(3, mgp, 0))

axis(3, at = scales::rescale(c(0, log10(0.03+1), log10(0.08+1)), to = c(0.3, 0.5), from = vi_range[[1]]),  
     labels = c(0, 0.03, 0.08), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(0, log10(10+1), log10(130+1)), to = c(0.3, 0.5), from = vi_range[[2]])+0.5, labels = c(0, 10, 130), tck = tck, mgp = c(3, mgp, 0))
#dev.off()

```

```{r}
#| echo: false
#| message: false

hyper_to_text = function(x, pre="", NN = FALSE) {x
  x = unlist(x)
  if(NN) x[[1]] = paste0("'", x[[1]], "'")
  return(paste0(paste0(paste0(pre, names(x)), "=", x, collapse = "\n"), "\n") )
}

settings = matrix(c(50, 100, 100, 100, 600, 100), ncol = 2, byrow = TRUE)

sapply(1:3, function(k) {
  tmp = as.integer(settings[k,])
  paths <<- c(
    paste0("results/NN_pars_",tmp[1],"_",tmp[2],"_replicate.RDS"),
    paste0("results/BRT_pars_",tmp[1],"_",tmp[2],"_replicate.RDS"),
    paste0("results/RF_pars_",tmp[1],"_",tmp[2],"_replicate.RDS"),
    paste0("results/Elastic_net_pars_",tmp[1],"_",tmp[2],"_replicate.RDS")
  )
  methods = c("NN", "BRT", "RF", "Elastic_net")
  results = lapply(1:4, function(i) {
    tmp = get_coefficients(i, gam = FALSE, path = paths[i], method = methods[i])$hyper$eff %>% select(-var_effect, -bias_zero, -var_zero, -bias_pred, -var_pred, -mse_eff, -mse_zero, -bias_effect, -mse_pred)
    names(tmp) = paste0(c("NN", "BRT", "RF", "EN")[i], "_", names(tmp))
    return(tmp)
    })
  conn = file(paste0("code/hyper-parameter/BIAS_hyper_param_config_",tmp[1],"_",tmp[2],".R"))
  writeLines(
    paste0(
      paste0("## Hyper-parameters for data-poor scenarios created by 'results.qmd' file\n"),
      hyper_to_text(results[[1]], NN = TRUE),
      hyper_to_text(results[[2]], NN = FALSE),
      hyper_to_text(results[[3]], NN = FALSE),
      hyper_to_text(results[[4]], NN = FALSE)), 
    conn )
  close(conn)
})


sapply(1:3, function(k) {
  tmp = as.integer(settings[k,])
  paths <<- c(
    paste0("results/NN_pars_",tmp[1],"_",tmp[2],"_replicate.RDS"),
    paste0("results/BRT_pars_",tmp[1],"_",tmp[2],"_replicate.RDS"),
    paste0("results/RF_pars_",tmp[1],"_",tmp[2],"_replicate.RDS"),
    paste0("results/Elastic_net_pars_",tmp[1],"_",tmp[2],"_replicate.RDS")
  )
  methods = c("NN", "BRT", "RF", "Elastic_net")
  results = lapply(1:4, function(i) {
    tmp = get_coefficients(i, gam=FALSE, path = paths[i], method = methods[i])$hyper$pred %>% select(-var_effect, -bias_zero, -var_zero, -bias_pred, -var_pred, -mse_eff, -mse_zero, -bias_effect, -mse_pred)
    names(tmp) = paste0(c("NN", "BRT", "RF", "EN")[i], "_", names(tmp))
    return(tmp)
    })
  conn = file(paste0("code/hyper-parameter/MSE_hyper_param_config_",tmp[1],"_",tmp[2],".R"))
  writeLines(
    paste0(
      paste0("## Hyper-parameters for data-poor scenarios created by 'create_hyper_config_.R' file\n"),
      hyper_to_text(results[[1]], NN = TRUE),
      hyper_to_text(results[[2]], NN = FALSE),
      hyper_to_text(results[[3]], NN = FALSE),
      hyper_to_text(results[[4]], NN = FALSE)), 
    conn )
  close(conn)
})

```

### Case Study


```{r}
#| label: fig-Fig_5
#| fig-format: pdf
#| fig-width: 5
#| fig-height: 2.3
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Difference between causal and conventional ML models for in-distribution and out-of-distribution predictions. In a simulated setting, the task is to predict Crop yield based on Plant growth (data-generating model is shown in the figure). Climate is an unobservable confounder and has effects on Plant growth and Pest (growth). In the first scenario, i.e. in-distribution predictions, Climate did not change, i.e. patients were exposed to the same climatic conditions; here the difference in predictive performance for the model with and without Pest growth is marginal (predictive performance was measured by R^2^). In the second theoretical setting, the climatic conditions changed (the effects of Climate on Plant growth and Pest are now zero). Using the previously trained models, the model without Pest deficit performed significantly worse than the model with Pest (plot with out-of-distribution predictions)."
methods = c("LM", "BRT", "RF","EN", "NN" )


results = readRDS("results/results_case_study.RDS")
results = apply(results, 2:3, mean)

rownames(results) = methods
colnames(results) = c("Conv_out", "Conv_in", "Causal_out", "Causal_in" )
results = data.frame(results, method = methods)
results = 
  results %>% 
    pivot_longer(c(Conv_out, Conv_in, Causal_out, Causal_in), names_to = "scenario", values_to = "R2") %>% 
    mutate(model = ifelse(stringr::str_detect(scenario, "Causal"), "Causal model", "Conventional model"),
           prediction = ifelse(stringr::str_detect(scenario, "out"), "out", "in")
           ) %>% 
    dplyr::select(-scenario)



results$method = as.factor(results$method)
results$method = forcats::lvls_reorder(results$method, c(3,5,1, 4, 2) )
results$model = as.factor(results$model)
results$model = forcats::lvls_reorder(results$model, c(2, 1))

res_ML = results %>% filter(method %in% c("RF", "BRT", "NN"))

g1 = 
  ggplot(res_ML %>% filter(prediction == "out"), 
         aes(y = R2, x = method, fill = model)) +
    geom_bar(stat="identity", color="black", 
             position=position_dodge(), show.legend = FALSE) +
    ggplot2::theme_bw() +
    xlab("Models") +
    ylab("R\U00B2") +
    ylim(0.0, 1.0) + 
    labs(tag = "a") +
    scale_fill_manual(values = rev(c("#00203FFF","#ADEFD1FF")))
g2 =
  ggplot(res_ML %>% filter(prediction == "in"), 
         aes(y = R2, x = method, fill = model)) +
    geom_bar(stat="identity", color="black", 
             position=position_dodge()) +
    ylab("R\U00B2") +
    xlab("Models") + 
    ggplot2::theme_bw() +
    ylim(0.0, 1.0) +
    labs(tag = "b") +
    scale_fill_manual(values = rev(c("#00203FFF","#ADEFD1FF"))) + 
    theme(legend.position = c(0.8, 0.8))
#cairo_pdf(filename = "plots/Fig_5.pdf", width = 5, height = 2.3)
gridExtra::grid.arrange(g1, g2, nrow = 1)
#dev.off()

```

