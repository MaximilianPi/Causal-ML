---
title: "Supporting information Appendix for Pichler & Hartig â€“ Can machine learning be used for causal inference?"
format: 
  docx:
    toc: true
    number-sections: true
    reference-doc: custom-reference-doc.docx
    keep-md: true
    fig-format: svg
crossref:
  fig-title: '**Figure S**'
  fig-labels: arabic
  tbl-title: '**Table S**'
  tbl-labels: arabic
  title-delim: ":"
bibliography: references.bib
---

```{r}
#| echo: false
#| message: false
library(ggplot2)
library(hrbrthemes)
library(viridis)
library(gridExtra)
library(tidyverse)
library(igraph)
library(glmmTMB)
library(flextable)
library(dplyr)
library(knitr)
library(kableExtra)
library(readr)
library(tidyr)
library(broom)
library(ggeffects)
library(gridExtra)
library(ranger)
library(xgboost)
library(torch)
library(cito)
library(glmnet)
library(glmnetUtils)
library(MASS)
Sys.setenv(OMP_NUM_THREADS=5)

source("code/AME.R")
source("code/Scenarios.R")
source("utils.R")

set_flextable_defaults(
  font.size = 8, theme_fun = theme_vanilla)

knitr::opts_chunk$set(fig.path="plots/", echo = FALSE)

```

**Summary:** This document provides supporting information on Pichler & Hartig -- Can machine learning be used for causal inference.

## Boosting and regression trees

### Unbiasedness

Random forest (RF) and boosted regression trees (BRT) showed bias in both scenarios, with and without collinearity, raising the question of whether the bias is caused by the boosting/bagging or the regression trees themselves. For RF, we know that the observed spillover effect is caused by the random subsampling (mtry parameter) in the algorithm, which explains the bias.

For BRT, however, it is unclear what is causing the bias (boosting or regression trees) because each member in the ensemble is always presented with all features (at least with the default hyperparameters, the BRT implementation in xgboost has options to use bootstrap samples for each tree and also subsamples of columns in each tree (or node), see @chen2016xgboost).

To understand how boosting and regression trees affect effect estimates, we simulated three different scenarios (Fig. S1, first column) without collinearity (Fig. S1a) and with collinearity (Fig. S1a, b) (we sampled 2000 observations from each data generating model (Fig. S1, first column) and estimated effects using MCE (100 repititions)).

```{r}
#| echo: false
#| message: false

results = readRDS("results/boosting_regression_trees.RDS")
methods = c("Linear booster", "Regression Tree LC", "Regression Tree HC", "Tree Booster LC", "Tree Booster HC", "LM")
results = lapply(results, function(r) {
  rownames(r) = methods
  r = r[c(6, 2, 3, 1, 4, 5),]
  return(r)
  })

no_coll = results[[4]]
coll = results[[3]]
conf = results[[2]]

plot_results = list(no_coll, coll, conf)
```

```{r}
#| label: fig-Fig_S1
#| fig-cap: "Bias on effect estimates for different ML algorithms (LM = liner regression model (OLS), RT LC = regression tree with low complexity (depth), RT HC = regression tree with high complexity, Linear Booster, Tree Booster LC = tree booster with low complexity, Tree Booster HC = tree boster with high complexity) in three different simulated causal scenarios (a, b, and c). Sample sizes are so large that stochastic effects can be excluded (2000 observations). Effects of the ML models were inferred using marginal conditional effects. Row a) shows results for simulations with uncorrelated features with the true effect sizes . Row b) shows the results for simulations with X~1~ and X~2~ being strongly correlated (Pearson correlation factor = 0.9) but only X~1~ has an effect on y (mediator) and row c) shows the results for X~1~ and X~2~ being strongly correlated (Pearson correlation factor = 0.9) with X~1~ and X~2~ having effects on Y (confounder scenario)."
#| fig-width: 14
#| fig-height: 10
#| warning: false
#| message: false

parser = function(true, bias, pos = 1) {
  if(pos == 1) { 
    yp = 1.25
    xp = 0.15
  }
  if(pos == 3) {
    yp = 1.63
    xp = -0.05
  }
  if(pos == 2) {
    yp = 0.37
    xp = -0.05
  }
  bb = round(bias, 2)
  if(bb > 0) { 
    symb = "+" 
    if(abs(bb) > 0.001) text(x = xp + 0.280, y = yp+0.01, pos = 4, symb, cex = 1.3, col = "#e60000", font = 2)
  } else { 
    symb = "-"
      if(abs(bb) > 0.001) text(x = xp + 0.29, y = yp, pos = 4, symb, cex = 1.3, col = "#e60000", font = 2)
    }
  bb = abs(bb)
   text(x = xp, y = yp, pos = 4,label = format(true, nsmall = 2), cex = 1.3)

  if(bb> 0.001) text(x = xp+ 0.35, y = yp, pos = 4, label = format(bb, nsmall = 2), cex = 1.3, col = "#e60000", font = 1)
}


par(mfcol = c(3,7), mar = c(5,0.5, 2, 1.4), oma = c(1, 2, 2, 1))
labs =  c("LM","RT LC", "RT HC",  "Linear Booster", "Tree Booster LC", "Tree Booster HC")
cex_fac = 1.3
minArrow = function(x) sapply(x, function(xx) max(c(0.1, xx)))

true_effs = matrix(c(
  1, 0.0, 1,
  1, 0.0, 1,
  1, 0.5, 1
), 3, 3, byrow = TRUE)

# A simulation
g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"),  
            directed=TRUE ) 
#layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE)
eqarrowPlot(g1, matrix(c(1,1,
                         0,1,
                         0,0,
                         0,2), nrow = 4L, 2L, byrow = TRUE) ,
            cols = c(addA(rep("#87CEEB", 1), 1.0), "#B0A8B9", addA(rep("#87CEEB", 1), 1.0), addA(rep("#87CEEB", 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.1, 1.0)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("",3),
            edge.label.cex = 1.4,
            edge.colors = rep("#B0A8B9", 3))
  text(letters[1], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
  text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.0, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)

# B simulation
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
            cols = c(addA(rep("#87CEEB", 1), 1.0), "#B0A8B9", addA(rep("#87CEEB", 1), 1.0), addA(rep("#87CEEB", 2), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.1, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            edge.arrow.mode = c(rep(">", 3), "-"), 
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
text(letters[2], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.0, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)

# C simulation
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
            cols = c(addA(rep("#87CEEB", 1), 1.0), "#B0A8B9", addA(rep("#87CEEB", 1), 1.0), addA(rep("#87CEEB", 2), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.5, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            edge.arrow.mode = c(rep(">", 3), "-"), 
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
text(letters[2], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.5, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)
points(x = 0, y = -0.55, col = "grey", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.55, label = "True effect", xpd = NA, pos = 4, cex = 1.4)
points(x = 0, y = -0.75, col = "#ffab02", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.75, label = "Correlation", xpd = NA, pos = 4, cex = 1.4)



for(i in 1:6) {
  counter = 1
  for(j in 1:3) {

    tmp = plot_results[[j]]
    edges = round(tmp[i,], 5)
    bias = edges[c(1, 2, 5)] - true_effs[j,]
    g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"),  
                directed=TRUE ) 
    layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE)
    eqarrowPlot(g1, matrix(c(1,1,
                             0,1,
                             0,0,
                             0,2), nrow = 4L, 2L, byrow = TRUE) ,
                cols = c(addA(rep("#87CEEB", 1), 1.0), "#B0A8B9", addA(rep("#87CEEB", 1), 1.0), addA(rep("#87CEEB", 1), 1.0)),
                edge.arrow.size=minArrow(abs(-true_effs[j,] - bias)),#abs(edges[c(1, 2, 5)]), 
                edge.width=abs(-true_effs[j,] - bias)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
                edge.label = rep("",3),
                edge.label.cex = 1.4,
                edge.colors = ifelse(abs(bias) < 0.01, "#B0A8B9", "#e60000"))
    parser(true_effs[j, 1], bias[1], pos = 1)
    parser(true_effs[j, 2], bias[2], pos = 2)
    parser(true_effs[j, 3], bias[3], pos = 3)
    text(labs[i], x = 0, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
    if(i == 1) {
      text(letters[counter], cex = 1.9, x = -2.2, y = 2.5, xpd = NA, font = 2)
      counter = counter + 1
    }

  }
  if(i == 3) {
    points(x = 0-1, y = -1.1*0.5, col = "#e60000", xpd = NA, pch = 15, cex = 1.8)
    text(x = 0.1-1, y = -1.1*0.5, label = "Bias", xpd = NA, pos = 4, cex = 1.4)
  }
}

```

We found that the regression tree (RT) is unable to estimate unbiased effects (Fig. S1), regardless of the presence or absence of collinearity or the complexity of the RT (depth of the regression trees). Without collinearity, effects in regression trees were biased toward zero, less so with higher complexity (Fig. S1). With collinearity, there was a small spillover effect for the RT with high complexity (Fig. S1b) to the collinear zero effect (X~2~), similar to an l2 regularization. When the collinear feature (X~2~) had an effect (Fig. S1c), we found a stronger absolute bias for the smaller of the two collinear effects (X~2~), confirming our expectation that RTs show a greedy effect. This greedy behavior was particularly strong for the low complexity RT (Fig. S1c).

To answer the question of how boosting affects the greediness and spillover effects of RT, we first investigated the behavior of a linear booster because of the well-known behavior of OLS under collinearity. And indeed, we found that the linear booster was unbiased in all three scenarios (compare LM and linear booster in Fig. S1), showing that boosting itself can produce unbiased effects.

Now, comparing the vanilla BRTs with low and high complexity (depth of individual trees) with the linear booster and the RTs, we found similar biases as for the RTs, in terms of spillover with a collinear zero effect and the greediness effect in the presence of a weaker collinear effect (Fig. S1).

### Understanding boosting

Intuitive boosting shouldn't work because it's basically a regression of residuals. That is, and in the case of collinearity, the stronger of two collinear features in the first model would absorb the effect of the weaker second feature that, for example, causes the omitted variable bias (the effect of the missing confounder is absorbed by the collinear effect).

```{r}
#| warning: false
#| message: false
set.seed(42)
sim = function() simulate(r = 0.9, effs = c(1, 0.5, 0, 0, 1, seq(-0.2, 0.2, length.out = 10)),n = 500)
data = sim()
data[,-1] = scale(data[,-1])

m = get_boosting_model(x = data[,-1], y = data[,1], n_trees = 100, booster = "linear")

eff_change =
  sapply(1:100, function(i) {
    m$N = i
    eff = diag(marginalEffects(m, data = data.frame(data)[,-1], interactions = FALSE, max_indices = 5)$mean)
    return(eff)
  })

eff_relative =
  sapply(1:100, function(i) {
    tmp = m
    tmp$model = list(m$model[[i]])
    tmp$N = 1
    eff = diag(marginalEffects(tmp, data = data.frame(data)[,-1], interactions = FALSE, max_indices = 5)$mean)
    return(eff)
  })
```

```{r}
#| label: fig-Fig_S2
#| fig-cap: "Changes of effects within boosting. (A) shows the total effect of ensemble (linear booster) until the n-th ensemble member. (B) shows the effects of the n-th ensemble member. X1 and X2 were correlated (Pearson correlationf factor = 0.9)."
#| fig-width: 9
#| fig-height: 4.5
#| warning: false
#| message: false

cols = c("#0000FF", "black", "#FF0000")
par(mfrow = c(1, 2), mar = c(4, 4, 2, 2))
matplot(t(eff_change)[, c(1, 2, 5)], type = "l", lty = 1, las = 1, 
        xlab = "Number of boosters", 
        ylab = "Total effect size",
        lwd = 2,
        col = cols
        )
legend("topright", lty = 1, col = cols, legend = c("X1 (true effect = 1.0)",
                                                   "X2 (true effect = 0.5)",
                                                   "X5 (true effect = 1.0)"), bty = "n")
text(x = 0, y = 1.55, pos = 2, label = "A", xpd = NA, font = 2, cex = 1.2)
matplot(t(eff_relative)[, c(1, 2, 5)], type = "p", 
        lty = 1, las = 1, xlab = "n-th booster", ylab = "Effect of n-th booster", pch = 16,col = cols)
text(x = 0, y = 1.55, pos = 2, label = "B", xpd = NA, font = 2, cex = 1.2)
legend("topright", lty = 1, col = cols, legend = c("X1 (true effect = 1.0)",
                                                   "X2 (true effect = 0.5)",
                                                   "X5 (true effect = 1.0)"), bty = "n")

```

Looking at the evolution of the total effect within a linear booster model (Fig. S2a), we found indeed that the first members of the ensemble absorb the effect of the collinear effect (effect of X1 is absorbed by X1, Fig. S2a), but as members are added to the ensemble, the collinear effect (X2) slowly recovers the effect of the stronger collinear effect until both are at their correct effect estimate (Fig. S2a). This retrieval works by reversing the sign of each member's effect, so that X1, which initially has an effect of 1.5 (because it absorbed the effect of X2), has small negative effects in subsequent trees, while X2, which is initially estimated at 0, has small positive effects (Fig. S2b).

## Extending MCE to two-way interactions

MCE can be extended to \$n\$-dimensions to detect $n$ way feature interactions. Here, we extended MCEs to two dimensions to detect two-way feature interactions by asking what the change is of $\hat{f}(\cdot)$ when features $x_m$ and $x_k$ change together:

$$\mathbf{MCE}_{mk} = \frac{\partial^2 \hat{f} (\mathbf{X} )}{ \partial x_m \partial x_k }$$

We can approximate $\mathbf{MCE}_{mk}$ with the finite difference method:

$$
\mathbf{MCE}_{mk} \approx \frac{ \hat{f} (x_1, x_2, ..., x_m + h, x_k + h, ..., x_j ) }{2(h_m + h_k)} -  \frac{ \hat{f} (x_1, x_2, ..., x_m - h, x_k + h, ..., x_j ) }{2(h_m + h_k)} -  \frac{ \hat{f} (x_1, x_2, ..., x_m + h, x_k - h, ..., x_j ) }{2(h_m + h_k)} - \frac{ \hat{f} (x_1, x_2, ..., x_m - h, x_k - h, ..., x_j ) }{2(h_m + h_k)}
$$

$h_m$ and $h_k$ are set to $0.1 \cdot sd(x_m)$ and $0.1 \cdot sd(x_k)$. All features are centered and standardized.

## Hyperparameter tuning

We performed a hyperparameter search to check if and how hyperparameters influence differently or equally effect estimates and the prediction error, so does a model tune after the prediction error has biased effects? For that, we created simulation scenarios with 50, 100, 600, and 2000 observations and 100 features with effects ($beta_i, i = 1,...,100$) $\beta_1 = 1.0$, and $\beta_2$ to $\beta_3$ were equally spaced between 0.0 to 1.0 so that $\beta_2 = 0.0$ and $\beta_{100} = 1.0$.

Features were sampled from a multivariate normal distribution and all features were randomly correlated (Variance-covariance matrix $\Sigma$ was sampled from a LKJ-distribution with $\eta = 2.0$.

1,000 combinations of hyper-parameters were randomly drawn (Table S1). For each draw of hyperparameters, the data simulation and model fitting was repeated 20 times. Effect sizes of X~1~ and X~2~ were recorded (for each hyperparameter combination and for each reptition). Moreover, bias, variance, and mean square error (MSE) were recorded for the predictions on a holdout of the same size as the training data.

| Algorithm               | Hyper-parameter       | Range                                             |
|-------------------|-------------------|----------------------------------|
| Neural Network          | activation function   | \[relu, leaky_relu, tanh, selu, elu, celu, gelu\] |
|                         | depth                 | \[1, 8\]                                          |
|                         | width                 | \[2, 50\]                                         |
|                         | batch size (sgd)      | \[1, 100\] in percent                             |
|                         | lambda                | \[2.65e-05, 0.16\]                                |
|                         | alpha                 | \[0, 1.0\]                                        |
| Boosted Regression Tree | eta                   | \[0.01, 0.4\]                                     |
|                         | max depth             | \[2, 25\]                                         |
|                         | subsample             | \[0.5, 1\]                                        |
|                         | max tree              | \[30, 125\]                                       |
|                         | lambda                | \[1, 20\]                                         |
| Random Forest           | mtry                  | \[0, 1\] in percent                               |
|                         | min node size         | \[2, 70\]                                         |
|                         | max depth             | \[2, 50\]                                         |
|                         | regularization factor | \[0, 1\]                                          |
| Elastic net             | alpha                 | \[0, 1.0\]                                        |
|                         | lambda                | \[0, 1.0\]                                        |

: Overview over hyper-parameters for Neural Network, Boosted Regression Tree, and Random Forest {#tbl-Hyper}

### Results hyperparameter tuning

```{r}
#| label: fig-Fig_S3
#| fig-cap: "Results of hyperparameter tuning for Neural Networks (NN), Boosted Regression Trees (BRT), Random Forests (RF), and Elastic Net (EN) for 50 observations with 100 features. The influence of the hyperparameters on the effect X~1~ (bias, variance, and MSE), the true simulated effect X~1~ = 1.0, and the predictions of the model (bias, variance, and MSE) were estimated by a multivariate generalized additive model (GAM). Categorical hyperparameters (activation function in NN) were estimated as fixed effects. The responses (bias, variance, MSE) were centered so that the categorical hyperparameters correspond to the intercepts. The variable importance of the hyperparameters was estimated by a random forest with the MSE of the effect X~1~ (first plot) or the prediction (second plot) as the response. Orange dots correspond to the best predicted set of hyperparameters (based on a random forest), in the first plot for the minimum MSE of the effect for X~1~ and in the second plot for the minimum MSE of the predictions."
#| fig-width: 9
#| fig-height: 10
#| warning: false
#| message: false

results_50 = readRDS("results/hyper_parameter_aggregation_50.RDS")
data = do.call(rbind, lapply(results_50, function(r) r$data))

labels = c("CELU",
           "ELU",
           "GELU",
           "Leaky ReLU",
           "ReLU",
           "SELU",
           "tanh",
           "batch size",
           "depth",
           "width",
           "alpha",
           "lambda",
           "eta",
           "max depth",
           "subsample",
           "max tree",
           "mtry",
           "min node size",
           "max depth",
           "regularization factor")
names(labels) = c("activationscelu",
                  "activationselu",
                  "activationsgelu",
                  "activationsleaky_relu",
                  "activationsrelu",
                  "activationsselu",
                  "activationstanh",
                  "sgd",
                  "depth", 
                  "width",
                  "alpha", 
                  "lambda",
                  "eta",
                  "max_depth",
                  "subsample",
                  "max_tree",
                  "mtry",
                  "min.node.size",
                  "max.depth",
                  "regularization.factor")
tck = 0.015
mgp = 0.07
eff_range = list(eff_range2 = c(-0.5, 0.5),eff_range1 = c(-0.04, 0.04))
vi_range = list(c(0, 0.04), c(0, 2.5))
plot_tuning(data = data, results = results_50, eff_range = eff_range, vi_range = vi_range)
axis(3, at = scales::rescale(c(-0.25, 0.0, 0.25), to = c(0.02, 0.28), from = eff_range[[1]]), labels = c(-0.25, 0.0, 0.25), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(-0.02, 0.0, 0.02), to = c(0.02, 0.28), from = eff_range[[2]])+0.5, labels = c(-0.02, 0.0, 0.02), tck = tck, mgp = c(3, mgp, 0))

axis(3, at = scales::rescale(c(0, log10(0.03+1), log10(0.08+1)), to = c(0.3, 0.5), from = vi_range[[1]]),  
     labels = c(0, 0.03, 0.08), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(0, log10(10+1), log10(130+1)), to = c(0.3, 0.5), from = vi_range[[2]])+0.5, labels = c(0, 10, 130), tck = tck, mgp = c(3, mgp, 0))

```

```{r}
#| label: fig-Fig_S4
#| fig-cap: "Results of hyperparameter tuning for Neural Networks (NN), Boosted Regression Trees (BRT), Random Forests (RF), and Elastic Net (EN) for 600 observations with 100 features. The influence of the hyperparameters on the effect X~1~ (bias, variance, and MSE), the true simulated effect X~1~ = 1.0, and the predictions of the model (bias, variance, and MSE) were estimated by a multivariate generalized additive model (GAM). Categorical hyperparameters (activation function in NN) were estimated as fixed effects. The responses (bias, variance, MSE) were centered so that the categorical hyperparameters correspond to the intercepts. The variable importance of the hyperparameters was estimated by a random forest with the MSE of the effect X~1~ (first plot) or the prediction (second plot) as the response. Orange dots correspond to the best predicted set of hyperparameters (based on a random forest), in the first plot for the minimum MSE of the effect for X~1~ and in the second plot for the minimum MSE of the predictions."
#| fig-width: 9
#| fig-height: 10
#| warning: false
#| message: false

results_600 = readRDS("results/hyper_parameter_aggregation_600.RDS")
data = do.call(rbind, lapply(results_600, function(r) r$data))

labels = c("CELU",
           "ELU",
           "GELU",
           "Leaky ReLU",
           "ReLU",
           "SELU",
           "tanh",
           "batch size",
           "depth",
           "width",
           "alpha",
           "lambda",
           "eta",
           "max depth",
           "subsample",
           "max tree",
           "mtry",
           "min node size",
           "max depth",
           "regularization factor")
names(labels) = c("activationscelu",
                  "activationselu",
                  "activationsgelu",
                  "activationsleaky_relu",
                  "activationsrelu",
                  "activationsselu",
                  "activationstanh",
                  "sgd",
                  "depth", 
                  "width",
                  "alpha", 
                  "lambda",
                  "eta",
                  "max_depth",
                  "subsample",
                  "max_tree",
                  "mtry",
                  "min.node.size",
                  "max.depth",
                  "regularization.factor")

eff_range = list(eff_range2 = c(-0.5, 0.5),eff_range1 = c(-0.04, 0.04))
vi_range = list(c(0, 0.10), c(0, 2.5))
plot_tuning(data = data, results = results_600, eff_range = eff_range, vi_range = vi_range)
axis(3, at = scales::rescale(c(-0.25, 0.0, 0.25), to = c(0.02, 0.28), from = eff_range[[1]]), labels = c(-0.25, 0.0, 0.25), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(-0.02, 0.0, 0.02), to = c(0.02, 0.28), from = eff_range[[2]])+0.5, labels = c(-0.02, 0.0, 0.02), tck = tck, mgp = c(3, mgp, 0))

axis(3, at = scales::rescale(c(0, log10(0.05+1), log10(0.14+1)), to = c(0.3, 0.5), from = vi_range[[1]]),  
     labels = c(0, 0.05, 0.14), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(0, log10(10+1), log10(130+1)), to = c(0.3, 0.5), from = vi_range[[2]])+0.5, labels = c(0, 10, 130), tck = tck, mgp = c(3, mgp, 0))

```

### Optimal hyperparameters

The hyperparameters were chosen based on the lowest MSE for the predictive performance of the models (Table S2) and the lowest MSE for the effect ($\beta_1$) on X~1~ (Table S3). The selection of the best hyperparameters was done by first fitting a random forest (default parameters) with the MSE as response and the hyperparameters as features, and then using the set of hyperparameters that predicted the lowest MSE. 

```{r}
#| warning: false
#| message: false
results_100 = readRDS("results/hyper_parameter_aggregation_100.RDS")
#| echo: false
round_if_num = function(x) {
  if(any(is.numeric(x))) x = round(x, 3)
  return(x)
}
create_table = function(tmp1, tmp2, tmp3, method = "NN") {
  resHyper = rbind(tmp1, tmp2, tmp3)
  hyn = colnames(resHyper)
  paste0(
  sapply(1:ncol(resHyper), function(i) {
    if(i == 1) prefix = method
    else prefix = " "
  return(paste0("| ",prefix," | ", hyn[i], " | ", paste0(round_if_num(resHyper[,i]), collapse = " | "), " | \n"))
  } ), collapse = "")
}

input_eff = paste0(
"| Algorithm | Hyperparameter | n = 50 | n = 100 | n = 600 | \n",
"|-----------|-----------|-----------|-----------|-----------|\n",
create_table(results_50[[1]]$hyper$eff[,1:6], results_100[[1]]$hyper$eff[,1:6], results_600[[1]]$hyper$eff[,1:6], "NN"),
create_table(results_50[[2]]$hyper$eff[,1:5], results_100[[2]]$hyper$eff[,1:5], results_600[[2]]$hyper$eff[,1:5], "BRT"),
create_table(results_50[[3]]$hyper$eff[,1:4], results_100[[3]]$hyper$eff[,1:4], results_600[[3]]$hyper$eff[,1:4], "RF"),
create_table(results_50[[4]]$hyper$eff[,1:2], results_100[[4]]$hyper$eff[,1:2], results_600[[4]]$hyper$eff[,1:2], "EN"))

input_pred = paste0(
"| Algorithm | Hyperparameter | n = 50 | n = 100 | n = 600 | \n",
"|-----------|-----------|-----------|-----------|-----------|\n",
create_table(results_50[[1]]$hyper$pred[,1:6], results_100[[1]]$hyper$pred[,1:6], results_600[[1]]$hyper$pred[,1:6], "NN"),
create_table(results_50[[2]]$hyper$pred[,1:5], results_100[[2]]$hyper$pred[,1:5], results_600[[2]]$hyper$pred[,1:5], "BRT"),
create_table(results_50[[3]]$hyper$pred[,1:4], results_100[[3]]$hyper$pred[,1:4], results_600[[3]]$hyper$pred[,1:4], "RF"),
create_table(results_50[[4]]$hyper$pred[,1:2], results_100[[4]]$hyper$pred[,1:2], results_600[[4]]$hyper$pred[,1:2], "EN"))

```


`r input_pred`

: Best predicted set of hyperparameterfor ML algorithms (tuned after MSE of predictions) {#tbl-Hyper_selected_pred}

`r input_eff`

: Best predicted set of hyperparameterfor ML algorithms (tuned after MSE of effect X~1~) {#tbl-Hyper_selected_eff}

## Additional results for data-poor scenarios

### Prediction error of scenarios

```{r}
#| warning: false
#| message: false



extract_results = function(path, N = "small", tuned = "pred") {

  effs_true = c(1.0, 0.0)
  algorithms = c("LM", "RF", "BRT", "NN", "EN")
  inter_low = readRDS(path)
  mse = do.call(rbind, lapply(1:5, function(i) {data.frame(tuned = tuned,N = N,algorithm = algorithms[i], mse = sapply(inter_low, function(r) r[[i]][3]))}))
  #mse_sd = sapply(1:5, function(i) {sd(sapply(inter_low, function(r) r[[i]][3]))})

  return((mse))
}

res_pred =  do.call(rbind, lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_MSE.RDS"), n, "pred")))
res_eff = do.call(rbind, lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_BIAS.RDS"), n, "eff")))

res = rbind(res_pred, res_eff)
res[(res$algorithm == "LM") & (res$N %in% c("small", "mid")),]$mse = NA

res = res %>% mutate(N = as.factor(N), algorithm = as.factor(algorithm))

res$algorithm = forcats::lvls_reorder(res$algorithm, c(3, 5, 1, 4, 2))
levels(res$N) = c("N = 600", "N = 100", "N = 50")
res$N = forcats::lvls_reorder(res$N, c(3, 2, 1))
```


```{r}
#| label: fig-Fig_S5
#| fig-cap: "Prediction error (mean square error, MSE) of data poor simulations with optimal hyperparameters either tuned after the best MSE of the effect size (red) or the best MSE of the prediction error (blue)."
#| fig-width: 7
#| fig-height: 6
#| warning: false
#| message: false


g1 =ggplot(data = res, aes(x = algorithm, y = mse, fill = tuned)) +
  geom_boxplot() +
  facet_grid(N~.) + 
  theme_bw() +
  xlab("Algorithm") +
  ylab("MSE")+
  theme(legend.position = c(0.05, 0.26)) +
  theme(strip.background =element_rect(fill="white"))
g1
```


## Data-poor scenarios without collinearity

### Bias and variance of effects


```{r}
#| echo: false

effs_true = c(1.0, 0.0)
extract_B = function(RI, exponent = 1) {
  Bias = apply(abind::abind(lapply(1:length(RI), function(j) t(sapply(1:5, function(i) RI[[j]][[i]][1:2]  - effs_true))), along = 0L), 2:3, mean)**exponent
  Bias_1 = apply(Bias[,1, drop=FALSE], 1, mean)
  Bias_0 = apply(Bias[,2, drop=FALSE], 1, mean)
  return(cbind(Bias_1, Bias_0)) #, Bias_Inter_1, Bias_Inter_0))
}

extract_V= function(RI) {
  Var = apply(abind::abind(lapply(1:length(RI), function(j) t(sapply(1:5, function(i) RI[[j]][[i]][1:2] ))), along = 0L), 2:3, var)
  Var_1 = apply(Var[,1, drop=FALSE], 1, mean)
  Var_0 = apply(Var[,2, drop=FALSE], 1, mean)
  return(cbind(Var_1, Var_0))  #, Var_Inter_1, Var_Inter_0))
}

extract_results = function(path, N = "small", tuned = "pred") {

  effs_true = c(1.0, 0.0)
  
  inter_low = readRDS(path)
  bias_low = extract_B(inter_low, exponent = 1)
  var_low = extract_V(inter_low)
  mse = sapply(1:5, function(i) {mean(sapply(inter_low, function(r) r[[i]][3]))})
  

  return(list(bias = bias_low, var = var_low, mse = mse))
}

res_pred =  lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_MSE_no_coll.RDS"), n, "pred"))
res_eff = lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_BIAS_no_coll.RDS"), n, "eff"))

```

```{r}
#| label: fig-Fig_S6
#| fig-width: 10
#| fig-height: 7
#| fig-cap: "Bias and variance of estimated effects in data-poor situations. N = 50, 100, and 600 observations of 100 weakly correlated features were simulated. The effects of X~1~ and X~2~ were 1.0 and 0.0. The other 98 effects were equally spaced between 0 and 1. Models were fitted to the simulated data (1000 repititions) with the optimal hyperparameters (except for LM, which doesn't have hyperparameters). Hyperparameters were chosen based on the minimum MSE of an effect (green) or the prediction error (red). Bias and variance were calculated for X~1~ and X~2~. Effects were approximated using ACE."
#| warning: false


bias = res_pred[[1]]$bias[1, 1]
var = res_pred[[1]]$var[1, 1]
draw_stacked_bar = function(bias, var, xleft = 0.0, w = 0.15) {
  rect(xleft, 0, xleft+w, abs(bias), col = "#96c6ed" )
  rect(xleft, abs(bias), xleft+w, abs(bias)+var, col = "#e0acd5" )
}

methods2 = c("LM", "RF", "BRT", "NN", "EN")
methods2[-1] = paste0(methods2[-1], " tuned")
par(mfrow = c(3, 5), mar = c(1, 1, 1, 1)*0.5, oma = c(12, 4, 4, 4))
y_labels = c("N = 50", "N = 100", "N = 600")
for(j in 1:3) {
  for(i in 1:5) {
    plot(NULL, NULL, xlim = c(0, 1), ylim = c(0, 1), yaxt = "n", xaxt = "n", xaxs = "i", yaxs = "i", xlab = "", ylab = "")
    if( i > 1) {
      rect(0.5, 0, 1.0, 1.0, col = "#EDBD9660", border = NA)
      rect(0.0, 0, 0.5, 1.0, col = "#9BED9660", border = NA)

      draw_stacked_bar(xleft = 0.1, res_pred[[j]]$bias[i, 1], res_pred[[j]]$var[i, 1])
      draw_stacked_bar(xleft = 0.1+0.18, res_pred[[j]]$bias[i, 2], res_pred[[j]]$var[i, 2])
      draw_stacked_bar(xleft = 0.1+0.47, res_eff[[j]]$bias[i, 1], res_eff[[j]]$var[i, 1])
      draw_stacked_bar(xleft = 0.1+0.18+0.47, res_eff[[j]]$bias[i, 2], res_eff[[j]]$var[i, 2])
    } else {
      
      if( ((j %in% c(1, 2)) && (i == 1) )) {
        text(x = 0.5, y = 0.5, pos = 3, label = "NA", font = 2)
      } else {
        draw_stacked_bar(xleft = 0.325, res_pred[[j]]$bias[i, 1], res_pred[[j]]$var[i, 1])
        draw_stacked_bar(xleft = 0.325+0.18, res_pred[[j]]$bias[i, 2], res_pred[[j]]$var[i, 2])

        text(x = c(0.185, 0.185+0.18),y = -0.24, 
        labels = c("Bias+Variance X1", "Bias+Variance X2"), 
        srt = 45,
        xpd = NA, pos = 1)        
      }
      
    }
    if(j == 1) {
      rect(0, 1.0, 1.0, 1.15, xpd = NA, border = "black")
      text(0.5, y = 0.98, pos = 3, xpd = NA, label = methods2[i], cex = 1.3, font = 2)
    }
    if(i == 5) {
      rect(1, 0, 1.15, 1.0, xpd = NA, border = "black")
      text(y = 0.72, x = 1.01, pos = 4, xpd = NA, label = y_labels[j], cex = 1.3, font = 2, srt = -90)
    }
    if( (j == 3) && (i > 1) ){
      text(x = c(0.185, 0.185+0.18, c(0.185, 0.185+0.18)+0.47)-0.22,y = -0.24, 
           labels = c("Bias+Variance X1", "Bias+Variance X2", "Bias+Variance X1", "Bias+Variance X2"), 
           srt = 45,
           xpd = NA, pos = 1)
    }    
  }
}

points(pch = 15, x = rep(-1.0, 2), y = c(-0.7, -0.8), xpd = NA, col = c("#96c6ed","#e0acd5"), cex = 1.5)
text(x = rep(-1.0, 2)+0.01, y = c(-0.7, -0.8)-0.02, pos = 4, labels = c("Bias", "Variance"), xpd = NA)

points(pch = 15, x = rep(-0.2, 2), y = c(-0.7, -0.8), xpd = NA, col = c("#9BED96","#EDBD96"), cex = 1.5)
text(x = rep(-0.2, 2)+0.01, y = c(-0.7, -0.8)-0.02, pos = 4, labels = c("Tuned after MSE of predictions", "Tuned after MSE of X1"), xpd = NA)


```


### Predictions error of scenarios (without collinearity)

### Prediction error of scenarios

```{r}
#| warning: false
#| message: false

extract_results = function(path, N = "small", tuned = "pred") {

  effs_true = c(1.0, 0.0)
  algorithms = c("LM", "RF", "BRT", "NN", "EN")
  inter_low = readRDS(path)
  mse = do.call(rbind, lapply(1:5, function(i) {data.frame(tuned = tuned,N = N,algorithm = algorithms[i], mse = sapply(inter_low, function(r) r[[i]][3]))}))
  #mse_sd = sapply(1:5, function(i) {sd(sapply(inter_low, function(r) r[[i]][3]))})

  return((mse))
}

res_pred =  do.call(rbind, lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_MSE_no_coll.RDS"), n, "pred")))
res_eff = do.call(rbind, lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_BIAS_no_coll.RDS"), n, "eff")))

res = rbind(res_pred, res_eff)
res[(res$algorithm == "LM") & (res$N %in% c("small", "mid")),]$mse = NA

res = res %>% mutate(N = as.factor(N), algorithm = as.factor(algorithm))

res$algorithm = forcats::lvls_reorder(res$algorithm, c(3, 5, 1, 4, 2))
levels(res$N) = c("N = 600", "N = 100", "N = 50")
res$N = forcats::lvls_reorder(res$N, c(3, 2, 1))
```


```{r}
#| label: fig-Fig_S7
#| fig-cap: "Prediction error (mean square error, MSE) of data poor simulations with optimal hyperparameters either tuned after the best MSE of the effect size (red) or the best MSE of the prediction error (blue)."
#| fig-width: 7
#| fig-height: 6
#| warning: false
#| message: false


g1 =ggplot(data = res, aes(x = algorithm, y = mse, fill = tuned)) +
  geom_boxplot() +
  facet_grid(N~.) + 
  theme_bw() +
  xlab("Algorithm") +
  ylab("MSE")+
  theme(legend.position = c(0.05, 0.26)) +
  theme(strip.background =element_rect(fill="white"))
g1
```



## Detecting interactions




<!-- ## Proof of concept - Additional results -->

<!-- ```{r} -->

<!-- #| echo: false -->

<!-- files =        c("collinearity_0.5.RDS", -->

<!--                  "collinearity_0.90.RDS", -->

<!--                  "collinearity_0.99.RDS", -->

<!--                  "effects.RDS", -->

<!--                  "no_effects.RDS", -->

<!--                  "confounder_unequal.RDS", -->

<!--                  "confounder.RDS") -->

<!-- Results = -->

<!--   lapply(files, function(f) { -->

<!--     confounder = readRDS(paste0("results/",f)) -->

<!--     Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:100, function(i) confounder[[i]][[j]][[1]] ), along = 0L), 2, mean)))) -->

<!--     colnames(Result) = LETTERS[1:5] -->

<!--     rownames(Result) = c("LM", "RF", "BRT", "NN", "Dropout", "l1", "l2", "l1l2") -->

<!--     return(Result) -->

<!--   }) -->

<!-- names(Results) = unlist(strsplit(files, ".RDS", TRUE)) -->

<!-- Results_rmse = -->

<!--   lapply(files, function(f) { -->

<!--     confounder = readRDS(paste0("results/",f)) -->

<!--     Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:100, function(i) confounder[[i]][[j]][[2]] ), along = 0L), 2, mean)))) -->

<!--     #colnames(Result) = LETTERS[1:5] -->

<!--     rownames(Result) = c("LM", "RF", "BRT", "NN", "Dropout", "l1", "l2", "l1l2") -->

<!--     return(Result) -->

<!--   }) -->

<!-- names(Results_rmse) = unlist(strsplit(files, ".RDS", TRUE)) -->

<!-- Results_rmse_sd = -->

<!--   lapply(files, function(f) { -->

<!--     confounder = readRDS(paste0("results/",f)) -->

<!--     Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:100, function(i) confounder[[i]][[j]][[2]] ), along = 0L), 2, sd)))) -->

<!--     #colnames(Result) = LETTERS[1:5] -->

<!--     rownames(Result) = c("LM", "RF", "BRT", "NN", "Dropout", "l1", "l2", "l1l2") -->

<!--     return(Result) -->

<!--   }) -->

<!-- names(Results_rmse_sd) = unlist(strsplit(files, ".RDS", TRUE)) -->

<!-- Results_sd = -->

<!--   lapply(files, function(f) { -->

<!--     confounder = readRDS(paste0("results/",f)) -->

<!--     Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:100, function(i) confounder[[i]][[j]][[1]] ), along = 0L), 2, sd)))) -->

<!--     colnames(Result) = LETTERS[1:5] -->

<!--     rownames(Result) = c("LM", "RF", "BRT", "NN", "Dropout", "l1", "l2", "l1l2") -->

<!--     return(Result) -->

<!--   }) -->

<!-- names(Results_sd) = unlist(strsplit(files, ".RDS", TRUE)) -->

<!-- layout = matrix(c(0,10, -->

<!--                   0,5, -->

<!--                   0,0, -->

<!--                   5,5), nrow = 4L, 2L, byrow = TRUE) -->

<!-- ``` -->

<!-- All models (Fig. 2) showed small variances $<0.01$ (Fig. S7) -->

<!-- ```{r} -->

<!-- #| label: fig-Fig_S7 -->

<!-- #| fig-cap: 'Variances of effect estimates for different ML algorithms in three different simulated causal simulations (a, b, and c). Sample sizes are so large that stochastic effects can be excluded. Effects of the ML models were inferred using marginal conditional effects. Row a) shows results for simulations with uncorrelated features with effect sizes (x~1~: 1.0, x~2~: 0.5, x~3~: 1.0). Row b) shows the results for simulations with x~1~ and x~2~ being strongly correlated (Pearson correlation factor = 0.9) but only x~1~ has an effect on y (mediator) and row c) shows the results for x~1~ and x~2~ being strongly correlated (Pearson correlation factor = 0.9 with x~1~ and x~2~ having effects on y (confounder scenario)' -->

<!-- #| fig-width: 10 -->

<!-- #| fig-height: 9 -->

<!-- sc = c("no_effects", "effects", "confounder_unequal", "collinearity_0.90") -->

<!-- algorithms = c("LM","RF",  "BRT", "NN","Dropout", "l1", "l2", "l1l2") -->

<!-- par(mfcol = c(3,6), mar = c(5,0.5, 2, 1.4), oma = c(1, 2, 2, 1)) -->

<!-- labs =  c("LM","RF",  "BRT", "NN", "Dropout", "l1", "l2", "Elastic-net") -->

<!-- #plot_scenarios(1.0) -->

<!-- #dev.off() -->

<!-- cex_fac = 1.3 -->

<!-- plot_scenarios(1.0, layout = matrix(c(1,1, -->

<!--                              0,1, -->

<!--                              0,0, -->

<!--                              0,2), nrow = 4L, 2L, byrow = TRUE)) -->

<!-- true_effs = matrix(c( -->

<!--   NA, NA, NA, -->

<!--   0, 0.0, 0, -->

<!--   1, 1, 1, -->

<!--   1, 0, 1 -->

<!-- ), 4, 3, byrow = TRUE) -->

<!-- for(i in c(1, 2, 3, 4, 8)) { -->

<!--   counter = 1 -->

<!--   for(j in c(2, 4, 3)) { -->

<!--     tmp = Results_sd[[sc[j]]]**2 -->

<!--     sd = Results_sd[[sc[j]]][i,] -->

<!--     edges = round(tmp[i,], 5) -->

<!--     bias = edges[c(1, 2, 5)] #- true_effs[j,] -->

<!--     g1 = graph(c("X1", "Y", "X2", "Y", "X3", "Y"), -->

<!--                 directed=TRUE ) -->

<!--     layout_as_tree(g1, root = "Y", circular = TRUE, flip.y = TRUE) -->

<!--     eqarrowPlot(g1, matrix(c(1,1, -->

<!--                              0,1, -->

<!--                              0,0, -->

<!--                              0,2), nrow = 4L, 2L, byrow = TRUE) , -->

<!--                 #cols = c( "skyblue","#B0A8B9", "#B0A8B9", "#B0A8B9"), -->

<!--                 cols = c(addA(rep("#87CEEB", 1), 1.0), "#B0A8B9", addA(rep("#87CEEB", 1), 1.0), addA(rep("#87CEEB", 1), 1.0)), -->

<!--                 edge.arrow.size=abs(edges[c(1, 2, 5)]), -->

<!--                 edge.width=abs(edges[c(1, 2, 5)])*cex_fac, -->

<!--                 edge.label = c(paste0(format(round(bias, 2)[1], nsmall = 1), "\n\n"),paste0(format(round(bias, 2)[2], nsmall = 1), "\n"), paste0("", format(round(bias, 2)[3], nsmall=1))), -->

<!--                 edge.label.cex = 1.4, -->

<!--                 edge.colors = ifelse(abs(edges[c(1, 2, 5)]) < 0.001, "white", "grey")) -->

<!--     text(labs[i], x = 0, y = 2.3, xpd = NA, cex = 1.4, pos = 3) -->

<!--     if(i == 1) { -->

<!--       text(letters[counter], cex = 1.9, x = -2.2, y = 2.5, xpd = NA, font = 2) -->

<!--       counter = counter + 1 -->

<!--     } -->

<!--   } -->

<!--   if(i == 3) { -->

<!--     points(x = 0-1, y = -1.1*0.5, col = "#e60000", xpd = NA, pch = 15, cex = 1.8) -->

<!--     text(x = 0.1-1, y = -1.1*0.5, label = "Variance", xpd = NA, pos = 4, cex = 1.4) -->

<!--   } -->

<!-- } -->

<!-- ``` -->

<!-- ### NN with Dropout, LASSO, and Ridge -->

<!-- We additionally tested NN with dropout (rate = 0.2), LASSO regression, and Ridge regression for the proof-of-concept simulations. -->

<!-- ```{r} -->

<!-- #| label: fig-Fig_S8 -->

<!-- #| fig-cap: "Bias on effect estimates for additional ML algorithms (NN with Dropout, LASSO, and Ridge regression) in three different simulated causal simulations (a, b, and c).Sample sizes are so large that stochastic effects can be excluded. Effects of the ML models were inferred using marginal conditional effects. Row a) shows results for simulations with uncorrelated features with effect sizes (x~1~: 1.0, x~2~: 0.5, x~3~: 1.0). Row b) shows the results for simulations with x~1~ and x~2~ being strongly correlated (Pearson correlation factor = 0.9) but only x~1~ has an effect on y (mediator) and row c) shows the results for x~1~ and x~2~ being strongly correlated (Pearson correlation factor = 0.9 with x~1~ and x~2~ having effects on y (confounder scenario)" -->

<!-- #| fig-width: 10 -->

<!-- #| fig-height: 9 -->

<!-- sc = c("no_effects", "effects", "confounder_unequal", "collinearity_0.90") -->

<!-- algorithms = c("LM","RF",  "BRT", "NN","Dropout", "l1", "l2", "l1l2") -->

<!-- par(mfcol = c(3,4), mar = c(5,0.5, 2, 1.4), oma = c(1, 2, 2, 1)) -->

<!-- labs =  c("LM","RF",  "BRT", "NN","NN+Dropout", "LASSO", "Ridge", "Elastic-net") -->

<!-- #plot_scenarios(1.0) -->

<!-- #dev.off() -->

<!-- cex_fac = 1.3 -->

<!-- plot_scenarios(1.0, layout = matrix(c(1,1, -->

<!--                              0,1, -->

<!--                              0,0, -->

<!--                              0,2), nrow = 4L, 2L, byrow = TRUE)) -->

<!--     points(x = 0, y = -0.55, col = "grey", xpd = NA, pch = 15, cex = 1.8) -->

<!--     text(x = 0.1, y = -0.55, label = "True effect", xpd = NA, pos = 4, cex = 1.4) -->

<!--     points(x = 0, y = -0.75, col = "#ffab02", xpd = NA, pch = 15, cex = 1.8) -->

<!--     text(x = 0.1, y = -0.75, label = "Correlation", xpd = NA, pos = 4, cex = 1.4) -->

<!-- true_effs = matrix(c( -->

<!--   NA, NA, NA, -->

<!--   1, 0.5, 1, -->

<!--   -1, 0.5, 1, -->

<!--   1, 0, 1 -->

<!-- ), 4, 3, byrow = TRUE) -->

<!-- for(i in c(5, 6, 7)) { -->

<!--   counter = 1 -->

<!--   for(j in c(2, 4, 3)) { -->

<!--     tmp = Results[[sc[j]]] -->

<!--     edges = round(tmp[i,], 5) -->

<!--     bias = edges[c(1, 2, 5)] - true_effs[j,] -->

<!--     g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"), -->

<!--                 directed=TRUE ) -->

<!--     layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE) -->

<!--     eqarrowPlot(g1, matrix(c(1,1, -->

<!--                              0,1, -->

<!--                              0,0, -->

<!--                              0,2), nrow = 4L, 2L, byrow = TRUE) , -->

<!--                 #cols = c( "skyblue","#B0A8B9", "#B0A8B9", "#B0A8B9"), -->

<!--                 cols = c(addA(rep("#87CEEB", 1), 1.0), "#B0A8B9", addA(rep("#87CEEB", 1), 1.0), addA(rep("#87CEEB", 1), 1.0)), -->

<!--                 edge.arrow.size=abs(bias)*2.3,#abs(edges[c(1, 2, 5)]), -->

<!--                 edge.width=abs(bias)*cex_fac*2,#abs(edges[c(1, 2, 5)])*cex_fac, -->

<!--                 edge.label = c(paste0(format(round(bias, 2)[1], nsmall = 1), "\n\n"), -->

<!--                                paste0("          ",format(round(bias, 2)[2], nsmall = 1), "\n"), -->

<!--                                paste0("          ", format(round(bias, 2)[3], nsmall=1))), -->

<!--                 edge.label.cex = 1.4, -->

<!--                 edge.colors = ifelse(abs(edges[c(1, 2, 5)]) < 0.001, "white", "#e60000")) -->

<!--     text(labs[i], x = 0, y = 2.3, xpd = NA, cex = 1.4, pos = 3) -->

<!--     if(i == 1) { -->

<!--       text(letters[counter], cex = 1.9, x = -2.2, y = 2.5, xpd = NA, font = 2) -->

<!--       counter = counter + 1 -->

<!--     } -->

<!--   } -->

<!--   if(i == 3) { -->

<!--     points(x = 0-1, y = -1.1*0.5, col = "#e60000", xpd = NA, pch = 15, cex = 1.8) -->

<!--     text(x = 0.1-1, y = -1.1*0.5, label = "Bias = estiamted effect - true effect", xpd = NA, pos = 4, cex = 1.4) -->

<!--   } -->

<!-- } -->

<!-- ``` -->

<!-- All three methods showed biased estimates in the first scenario for effects without collinearity (Fig. S8). With collinearity, all three showed larger biases but Ridge regression showed the largest biases (Fig. S8). -->

<!-- ```{r} -->

<!-- #| label: fig-Fig_S9 -->

<!-- #| fig-cap: "Variances of effect estimates for additional ML algorithms (NN with Dropout, LASSO, and Ridge regression) in three different simulated causal simulations (a, b, and c). Sample sizes are so large that stochastic effects can be excluded. Effects of the ML models were inferred using marginal conditional effects. Row a) shows results for simulations with uncorrelated features with effect sizes (x~1~: 1.0, x~2~: 0.5, x~3~: 1.0). Row b) shows the results for simulations with x~1~ and x~2~ being strongly correlated (Pearson correlation factor = 0.9) but only x~1~ has an effect on y (mediator) and row c) shows the results for x~1~ and x~2~ being strongly correlated (Pearson correlation factor = 0.9 with x~1~ and x~2~ having effects on y (confounder scenario)" -->

<!-- #| fig-width: 10 -->

<!-- #| fig-height: 9 -->

<!-- sc = c("no_effects", "effects", "confounder_unequal", "collinearity_0.90") -->

<!-- algorithms = c("LM","RF",  "BRT", "NN","Dropout", "l1", "l2", "l1l2") -->

<!-- par(mfcol = c(3,4), mar = c(5,0.5, 2, 1.4), oma = c(1, 2, 2, 1)) -->

<!-- labs =  c("LM","RF",  "BRT", "NN","NN+Dropout", "LASSO", "Ridge", "Elastic-net") -->

<!-- cex_fac = 1.3 -->

<!-- plot_scenarios(1.0, layout = matrix(c(1,1, -->

<!--                              0,1, -->

<!--                              0,0, -->

<!--                              0,2), nrow = 4L, 2L, byrow = TRUE)) -->

<!--     points(x = 0, y = -0.55, col = "grey", xpd = NA, pch = 15, cex = 1.8) -->

<!--     text(x = 0.1, y = -0.55, label = "True effect", xpd = NA, pos = 4, cex = 1.4) -->

<!--     points(x = 0, y = -0.75, col = "#ffab02", xpd = NA, pch = 15, cex = 1.8) -->

<!--     text(x = 0.1, y = -0.75, label = "Correlation", xpd = NA, pos = 4, cex = 1.4) -->

<!-- true_effs = matrix(c( -->

<!--   NA, NA, NA, -->

<!--   1, 0.5, 1, -->

<!--   -1, 0.5, 1, -->

<!--   1, 0, 1 -->

<!-- ), 4, 3, byrow = TRUE) -->

<!-- for(i in c(5, 6, 7)) { -->

<!--   counter = 1 -->

<!--   for(j in c(2, 4, 3)) { -->

<!--     tmp = Results_sd[[sc[j]]]**2 -->

<!--     edges = round(tmp[i,], 5) -->

<!--     bias = edges[c(1, 2, 5)] #- true_effs[j,] -->

<!--     g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"), -->

<!--                 directed=TRUE ) -->

<!--     layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE) -->

<!--     eqarrowPlot(g1, matrix(c(1,1, -->

<!--                              0,1, -->

<!--                              0,0, -->

<!--                              0,2), nrow = 4L, 2L, byrow = TRUE) , -->

<!--                 #cols = c( "skyblue","#B0A8B9", "#B0A8B9", "#B0A8B9"), -->

<!--                 cols = c(addA(rep("#87CEEB", 1), 1.0), "#B0A8B9", addA(rep("#87CEEB", 1), 1.0), addA(rep("#87CEEB", 1), 1.0)), -->

<!--                 edge.arrow.size=abs(bias)*2.3,#abs(edges[c(1, 2, 5)]), -->

<!--                 edge.width=abs(bias)*cex_fac*2,#abs(edges[c(1, 2, 5)])*cex_fac, -->

<!--                 edge.label = c(paste0(format(round(bias, 2)[1], nsmall = 1), "\n\n"), -->

<!--                                paste0("          ",format(round(bias, 2)[2], nsmall = 1), "\n"), -->

<!--                                paste0("          ", format(round(bias, 2)[3], nsmall=1))), -->

<!--                 edge.label.cex = 1.4, -->

<!--                 edge.colors = ifelse(abs(edges[c(1, 2, 5)]) < 0.001, "white", "#e60000")) -->

<!--     text(labs[i], x = 0, y = 2.3, xpd = NA, cex = 1.4, pos = 3) -->

<!--     if(i == 1) { -->

<!--       text(letters[counter], cex = 1.9, x = -2.2, y = 2.5, xpd = NA, font = 2) -->

<!--       counter = counter + 1 -->

<!--     } -->

<!--   } -->

<!--   if(i == 6) { -->

<!--     points(x = 0-1, y = -1.1*0.5, col = "#e60000", xpd = NA, pch = 15, cex = 1.8) -->

<!--     text(x = 0.1-1, y = -1.1*0.5, label = "Variance", xpd = NA, pos = 4, cex = 1.4) -->

<!--   } -->

<!-- } -->

<!-- ``` -->

<!-- While estimates from NN with dropout had the smallest biases, they had the largest variances (Fig. S9), though these variances were still small (Fig. S9). -->

<!-- ### RMSE on holdout -->

<!-- In addition to bias and variance, we calculated the predictive error using the RMSE on holdout data which had the same size as the training data (N = 1000). -->

<!-- RF, BRT, and Dropout showed the highest RMSE in all three scenarios (Fig. S10). LASSO and elastic-net showed the smallest RMSE in all three scenarios (Fig. S10). -->

<!-- ```{r} -->

<!-- #| label: fig-Fig_S10 -->

<!-- #| fig-width: 7 -->

<!-- #| fig-height: 3 -->

<!-- #| fig-cap: "Root mean squared error (RMSE) for different ML algorithms in three different simulated causal simulations (a, b, and c). Sample sizes are so large that stochastic effects can be excluded. 1,000 observations were used to train the models and 1,000 observations were used to evaluate the predictive performance of the models. Column 'effects' shows results for simulations with uncorrelated features with effect sizes (x1: 1.0, x2: 0.5, x3: 1.0). Column 'collinearity_0.90' shows the results for simulations with x1 and x2 being strongly correlated (Pearson correlation factor = 0.9) but only x1 has an effect on y (mediator) and column 'confounder_unequal' shows the results for x1 and x2 being strongly correlated (Pearson correlation factor = 0.9 with x1 and x2 having effects on y (confounder scenario)." -->

<!-- res_rmse = do.call(rbind, lapply(Results_rmse, function(d) data.frame(values = d, method = rownames(d)))) -->

<!-- res_rmse$scenario = rep(names(Results_rmse), each = 8) -->

<!-- res_rmse$type = "rmse" -->

<!-- res_rmse_sd = do.call(rbind, lapply(Results_rmse_sd, function(d) data.frame(values = d, method = rownames(d)))) -->

<!-- res_rmse$var = res_rmse_sd$values -->

<!-- res_rmse = -->

<!--   res_rmse %>% -->

<!--            filter(scenario %in% sc[-1]) -->

<!-- res_rmse$method = forcats::lvls_reorder(res_rmse$method, c(6, 8, 1, 7, 4, 3, 5, 2)) -->

<!-- res_rmse$scenario = forcats::lvls_reorder(res_rmse$scenario, c(3, 1, 2)) -->

<!-- ggplot(res_rmse, aes(y=values, x=method)) + -->

<!--   geom_bar(stat = 'identity', fill = "lightgrey") + -->

<!--   geom_errorbar(aes(ymin=values-var, ymax=values+var), width=.2) + -->

<!--   facet_grid(~ scenario) + -->

<!--   theme_bw()  + -->

<!--   labs(x = "", y = "") + -->

<!--   theme(panel.grid.major.x = element_blank()) + -->

<!--   theme(strip.background = element_rect(fill = "white")) + -->

<!--   theme(strip.text = element_text(colour = 'black')) + -->

<!--   theme(strip.placement = "outside") + -->

<!--   theme(strip.text = element_text(hjust = 0.5)) + -->

<!--   theme(legend.position="bottom")+ -->

<!--   theme(axis.text.x = element_text(angle = 45, hjust=1)) -->

<!-- ``` -->

## Weighted MCE

If the instances of a feature x_j are not uniformly distributed, we propose to calculate a weighted $wMCE_k = \Sigma^{N}_{i=1} w_i MCE_{ik}$ with the $w_i$ being, for example, the inverse probabilities of an estimated density function over the feature space of $x_k$.

To demonstrate the idea of weighted MCE, we simulated a scenario with one feature where the $\beta_1 = 2$ for values of the feature $< 2$ and for the other feature values $\beta_1=0$ (Fig. S4). The feature was sampled from a log-Normal distribution. We fitted a linear regression model and a NN on the data and compared the effect estimated by the LM, the unweighted MCE, and the weighted MCE.

The LM estimated an effect of 1.48, the unweighted MCE was 1.95, and the weighted MCE was 1.48 (Fig. S16).

```{r}
#| label: fig-Fig_S16
#| message: false
#| fig-cap: Simulation example with non-uniform sampled feature X1 (log normal distributed). The red line is the effect estimated by a LM OLS. The blue line is the effect reported by an unweighted MCE from a NN. The green line is the effect reported by a weighted MCE from a NN. 
#| fig-width: 7
#| fig-height: 6
source("code/AME.R")

set.seed(42)
X1 = scale(rlnorm(1000, sdlog = 0.6))
X2 = rnorm(1000)
Y = rep(0, 1000)
Y[X1<2] = 2*X1[X1<2]
Y[X1>2] = 4
Y = Y + rnorm(1000, sd = 0.2)

library(cito)
dn = cito::dnn(Y~., data = data.frame(Y = Y, X1 = X1, X2 = X2), 
              activation = rep("relu", 3),
              hidden = rep(30L, 3),
              verbose = FALSE, 
              batchsize = 100, 
              epochs = 100L,
              shuffle = TRUE,
              loss = "mse",
              plot=FALSE, 
              lambda = 0.001, alpha = 1., 
              lr_scheduler = config_lr_scheduler("reduce_on_plateau", factor = 0.90, patience = 5))
M = (marginalEffects(dn))

effs = M$result[,1,1]
D = density(X1)
f = approxfun(density(X1))


m2 = (lm(Y~X1))
plot(X1, Y, las = 1, col = "darkgrey")
abline(m2, col = "red")
abline(0, mean(effs), col = "blue")
abline(0, sum((1/(f(X1))*effs))/sum(1/f(X1)), col = "darkgreen")
legend("bottomright", legend = c(paste0(round(coef(m2)[[2]], 2), "LM OLS "), 
                                 paste0(round(mean(effs), 2), " DNN aMCE"), 
                                 paste0(round(sum((1/(f(X1))*effs))/sum(1/f(X1)), 2), " DNN waMCE")
                                 ), col = c("red", "blue", "darkgreen"), lty = 1, bty = "n")

```

## Case study - RMSE

```{r}
#| label: tbl-Table_S4
#| tbl-cap: "In-sample R2 of BRT, RF, NN, and LM in predicting the risk of Lung Cancer"


coll_no = readRDS("results/res_changed_no.RDS")
coll_no_results = apply(coll_no [1:10, ,], 2:3, mean)
coll_no_results = as.data.frame(coll_no_results)[1:4,]
rownames(coll_no_results) = c("BRT", "RF", "NN", "LM")
colnames(coll_no_results) = c("H", "HT", "HO", "HOT")
data = coll_no_results
data$model = rownames(data)
data = data %>% pivot_longer(cols = c("H", "HT", "HO", "HOT")) 
data = data %>% filter(name %in% c("HO", "H"))
color = RColorBrewer::brewer.pal(4, "Set2")
labels = c("Conventional ML 1", "Causal ML")
data$name = forcats::lvls_reorder(data$name, c(2, 1))

levels(data$name) = c("Conventional ML 1", "Causal ML")
insample = data

ft = flextable((data %>% pivot_wider(names_from = model))) %>% colformat_double(digits = 2)
ft

```

```{r}
#| label: tbl-Table_S5
#| tbl-cap: "Out-of-sample R2 of BRT, RF, NN, and LM in predicting the risk of Lung Cancer with intervention on Lung Volume"

coll_no = readRDS("results/res_changed_intervention.RDS")
coll_no_results = apply(coll_no [1:10, ,], 2:3, mean)
coll_no_results = as.data.frame(coll_no_results)[1:4,]
rownames(coll_no_results) = c("BRT", "RF", "NN", "LM")
colnames(coll_no_results) = c("H", "HT", "HO", "HOT")
data = coll_no_results
data$model = rownames(data)
data = data %>% pivot_longer(cols = c("H", "HT", "HO", "HOT")) %>% filter(name %in% c("HO", "H"))
color = RColorBrewer::brewer.pal(4, "Set2")
labels = c("Conventional ML 1", "Causal ML")
data$name = forcats::lvls_reorder(data$name, c(2, 1))


levels(data$name) = c("Conventional ML 1", "Causal ML")
outofsample = data

ft = flextable((data %>% pivot_wider(names_from = model))) %>% colformat_double(digits = 2)
ft

```

```{r}
#| label: tbl-Table_S6
#| tbl-cap: "Out-of-sample R2 of BRT, RF, NN, and LM in predicting the risk of Lung Cancer with changed correlation structure because of the unobservable confounder Stress"

coll_no = readRDS("results/res_changed_coll.RDS")
coll_no_results = apply(coll_no [1:10, ,], 2:3, mean)
coll_no_results = as.data.frame(coll_no_results)[1:4,]
rownames(coll_no_results) = c("BRT", "RF", "NN", "LM")
colnames(coll_no_results) = c("H", "HT", "HO", "HOT")
data = coll_no_results
data$model = rownames(data)
data = data %>% pivot_longer(cols = c("H", "HT", "HO", "HOT")) %>% filter(name %in% c("HOT", "HT", "H"))
color = RColorBrewer::brewer.pal(4, "Set2")

data$name = forcats::lvls_reorder(data$name, idx = c(1,2 , 3))
labels = c("Conventional ML 1","Conventional ML 2", "Causal ML")


levels(data$name) = c("Conventional ML 1", "Conventional ML 2", "Causal ML")
outofsample_conf = data
ft = flextable((data %>% pivot_wider(names_from = model))) %>% colformat_double(digits = 2)
ft

```
