---
title: "Supporting information Appendix for Pichler & Hartig â€“ Can machine learning be used for causal inference?"
format: 
  docx:
    toc: true
    number-sections: true
    reference-doc: custom-reference-doc.docx
    keep-md: false
    fig-format: svg
crossref:
  fig-title: '**Figure S**'
  fig-labels: arabic
  tbl-title: '**Table S**'
  tbl-labels: arabic
  title-delim: ":"
bibliography: references.bib
---

```{r}
#| echo: false
#| message: false
library(ggplot2)
library(hrbrthemes)
library(viridis)
library(gridExtra)
library(tidyverse)
library(igraph)
library(glmmTMB)
library(flextable)
library(dplyr)
library(knitr)
library(kableExtra)
library(readr)
library(tidyr)
library(broom)
library(ggeffects)
library(gridExtra)
library(ranger)
library(xgboost)
library(torch)
library(cito)
library(glmnet)
library(glmnetUtils)
library(MASS)
library(latex2exp)
Sys.setenv(OMP_NUM_THREADS=5)

source("code/AME.R")
source("code/Scenarios.R")
source("utils.R")

set_flextable_defaults(
  font.size = 8, theme_fun = theme_vanilla)

knitr::opts_chunk$set(fig.path="figures/", echo = FALSE)

```

**Summary:** This document provides supporting information on Pichler & Hartig -- Can machine learning be used for causal inference.

## Extending ACE to two-way interactions

ACE can be extended to $n$-dimensions to detect $n$ way predictor interactions. Here, we extended ACEs to two dimensions to detect two-way predictor interactions by asking what the change is of $\hat{f}(\cdot)$ when predictors $x_m$ and $x_k$ change together:

$$\mathbf{ACE}_{mk} = \frac{\partial^2 \hat{f} (\mathbf{X} )}{ \partial x_m \partial x_k }$$

We can approximate $\mathbf{ACE}_{mk}$ with the finite difference method:

$$
\mathbf{ACE}_{mk} \approx \frac{ \hat{f} (x_1, x_2, ..., x_m + h, x_k + h, ..., x_j ) }{2(h_m + h_k)} -  \frac{ \hat{f} (x_1, x_2, ..., x_m - h, x_k + h, ..., x_j ) }{2(h_m + h_k)} -  \frac{ \hat{f} (x_1, x_2, ..., x_m + h, x_k - h, ..., x_j ) }{2(h_m + h_k)} - \frac{ \hat{f} (x_1, x_2, ..., x_m - h, x_k - h, ..., x_j ) }{2(h_m + h_k)}
$$

$h_m$ and $h_k$ are set to $0.1 \cdot sd(x_m)$ and $0.1 \cdot sd(x_k)$. All predictors are centered and standardized.


### Proof of concept simulations for inferring interactions

To test the ability of ML algorithms to identify predictor-predictor interactions, we repeated the proof-of-concept simulations, but with an interaction between X~1~ and X~2~. The data generation model was $Y\sim 1.0 \cdot X_1 + 1.0 \cdot X_5 + 1.0 \cdot (X_1 \cdot X_2) + \epsilon$ with  $\epsilon \sim N(0, 1.0) $. We simulated two scenarios, in the first ("collinear") X~1~ and X~2~ were collinear (Pearson correlation factor = 0.9) and in the second without collinearity between the predictors. 

We sampled 1000 and 5000 observations from each scenario. The ML algorithms (RF, BRT, NN, and NN with dropout) were fit to the data without predictor engineering the predictor interactions (because ML algorithms are known to be able to infer interactions automatically), while the regression algorithms (LM, l1, l2, and elastic-net) received all combinatorially possible predictor interactions as possible predictors. All effects were inferred using ACE. The bias was calculated for the interaction X~1~:X~2~.

```{r}
#| warning: false
#| message: false
collinear_results_1000 = readRDS("results/collinearity_0.90_interactions_1000.RDS")
collinear_results_5000 = readRDS("results/collinearity_0.90_interactions_5000.RDS")
effect_results_1000 = readRDS("results/effects_interactions_1000.RDS")
effect_results_5000 = readRDS("results/effects_interactions_5000.RDS")


transform_data = function(tmp, N = 1000, scenario = "effects") {
  tmp = t(apply(abind::abind(lapply(1:50, function(i) { sapply(1:8, function(j)  tmp[[i]][[j]][[1]][c(1,2, 6)] ) } ), along = 0L), 2:3, mean))
  
  colnames(tmp) = c("X1", "X2", "X1:X2")
  tmp = data.frame(tmp)
  tmp[,1] = 1-tmp[,1]
  tmp[,3] = 1 - tmp[,3]
  tmp$algorithm = c("LM", "RF", "BRT", "NN","NN Dropout", "L1", "L2", "EN")
  tmp$N = N
  tmp$scenario = scenario
  return(tmp)
}


collinear_res_1000 = transform_data(collinear_results_1000, 1000, "collinear")
collinear_res_5000 = transform_data(collinear_results_5000, 5000, "collinear")
effect_res_1000 = transform_data(effect_results_1000, 1000, "effect")
effect_res_5000 = transform_data(effect_results_5000, 5000, "effect")


results = rbind(collinear_res_1000, collinear_res_5000, effect_res_1000, effect_res_5000)
res = results %>% 
  pivot_longer(cols = c(X1, X2, X1.X2)) %>% 
  mutate(algorithm = as.factor(algorithm), scenario = as.factor(scenario), name = as.factor(name))
res$algorithm = forcats::lvls_reorder(res$algorithm, c(8, 1, 6, 7, 5, 3, 4, 2))
res$name = forcats::lvls_reorder(res$name, c(1, 3, 2))
res$N = as.factor(res$N)
```

```{r}
#| label: fig-Fig_S1
#| fig-cap: "Bias of proof of concept simulations in inferring two-way interactions between predictors. First panel shows results for simulations (200 repititions) for 1000 and 5000 observations with collinear predictors (Pearson correlation factor = 0.9 between X~1~ and X~2~). Second panel shows results for simulations (200 repititions) for 1000 and 5000 observations with without collinear. Red bars correspond to 1000 observations and blue bars to 5000 observations. "
#| fig-width: 8
#| fig-height: 4.5
#| warning: false
#| message: false

ggplot(data = res %>% filter(name == "X1.X2"), aes(x = algorithm, fill = N, y = value)) + 
  geom_bar(position="dodge", stat="identity") +
  facet_grid(~scenario) +
  theme_bw() + 
  ylab("Bias") +
  theme(legend.position = c(.85, 0.76)) +
  theme(strip.background =element_rect(fill="white"))
```

We found that for the ML algorithms (RF, BRT, and NN) NN showed the lowest for all scenarios (Fig. S1). Also collinearity increased the bias for the ML algorithms. No collinearity or more observations decreased the bias (Fig. S1). The regression models, LM, LASSO and Ridge regression, and elastic-net showed the lowest and in case of LM, no bias. However, we want to note here that the regression models received all possible predictor-predictor interactions as predictors while the ML algorithms had to infer the interactions on their own. Whit this in mind, the performance of the NN is surprising well, even competing with the penalized regression models. On the other hand, NN with dropout showed larger biases than BRT (Fig. S1).

### Weighted ACE

If the instances of a predictor x_j are not uniformly distributed, we propose to calculate a weighted $wACE_k = \Sigma^{N}_{i=1} w_i ACE_{ik}$ with the $w_i$ being, for example, the inverse probabilities of an estimated density function over the predictor space of $x_k$.

To demonstrate the idea of weighted ACE, we simulated a scenario with one predictor where the $\beta_1 = 2$ for values of the predictor $< 2$ and for the other predictor values $\beta_1=0$ (Fig. S2). The predictor was sampled from a log-Normal distribution. We fitted a linear regression model and a NN on the data and compared the effect estimated by the LM, the unweighted ACE, and the weighted ACE.

The LM estimated an effect of 1.48, the unweighted ACE was 1.95, and the weighted ACE was 1.48 (Fig. S2).

```{r}
#| label: fig-Fig_S2
#| message: false
#| fig-cap: Simulation example with non-uniform sampled predictor X1 (log normal distributed). The red line is the effect estimated by a LM OLS. The blue line is the effect reported by an unweighted ACE from a NN. The green line is the effect reported by a weighted ACE from a NN. 
#| fig-width: 7
#| fig-height: 6
source("code/AME.R")

set.seed(42)
X1 = scale(rlnorm(1000, sdlog = 0.6))
X2 = rnorm(1000)
Y = rep(0, 1000)
Y[X1<2] = 2*X1[X1<2]
Y[X1>2] = 4
Y = Y + rnorm(1000, sd = 0.2)

library(cito)
dn = cito::dnn(Y~., data = data.frame(Y = Y, X1 = X1, X2 = X2), 
              activation = rep("relu", 3),
              hidden = rep(30L, 3),
              verbose = FALSE, 
              batchsize = 100, 
              epochs = 100L,
              shuffle = TRUE,
              loss = "mse",
              plot=FALSE, 
              lambda = 0.001, alpha = 1., 
              lr_scheduler = config_lr_scheduler("reduce_on_plateau", factor = 0.90, patience = 5))
M = (marginalEffects(dn))

effs = M$result[,1,1]
D = density(X1)
f = approxfun(density(X1))


m2 = (lm(Y~X1))
plot(X1, Y, las = 1, col = "darkgrey")
abline(m2, col = "red")
abline(0, mean(effs), col = "blue")
abline(0, sum((1/(f(X1))*effs))/sum(1/f(X1)), col = "darkgreen")
legend("bottomright", legend = c(paste0(round(coef(m2)[[2]], 2), "LM OLS "), 
                                 paste0(round(mean(effs), 2), " DNN aACE"), 
                                 paste0(round(sum((1/(f(X1))*effs))/sum(1/f(X1)), 2), " DNN waACE")
                                 ), col = c("red", "blue", "darkgreen"), lty = 1, bty = "n")

```


## Boosting and regression trees

### Unbiasedness

Random forest (RF) and boosted regression trees (BRT) showed biased effect estimates in both scenarios, with and without collinearity, raising the question of whether the bias is caused by the boosting/bagging or the regression trees themselves. For RF, we know that the observed spillover effect is caused by the random subsampling (mtry parameter) in the algorithm, which explains the bias.

For BRT, however, it is unclear what is causing the bias (boosting or regression trees) because each member in the ensemble is always presented with all predictors (at least with the default hyperparameters, the BRT implementation in xgboost has options to use bootstrap samples for each tree and also subsamples of columns in each tree (or node), see @chen2016xgboost).

To understand how boosting and regression trees affect effect estimates, we simulated three different scenarios (Fig. S3, first column) without collinearity (Fig. S3a) and with collinearity (Fig. S3a, b) (we sampled 1000 observations from each data generating model (Fig. S3, first column) and estimated effects using ACE (500 repititions)).

```{r}
#| echo: false
#| message: false

results = readRDS("results/boosting_regression_trees.RDS")
methods = c("Linear booster", "Regression Tree LC", "Regression Tree HC", "Tree Booster LC", "Tree Booster HC", "LM")
results = lapply(results, function(r) {
  rownames(r) = methods
  r = r[c(6, 2, 3, 1, 4, 5),]
  return(r)
  })

no_coll = results[[4]]
coll = results[[3]]
conf = results[[2]]

plot_results = list(no_coll, coll, conf)
```

```{r}
#| label: fig-Fig_S3
#| fig-cap: "Bias on effect estimates for different ML algorithms (LM = liner regression model (OLS), RT LC = regression tree with low complexity (depth), RT HC = regression tree with high complexity, Linear Booster, Tree Booster LC = tree booster with low complexity, Tree Booster HC = tree boster with high complexity) in three different simulated causal scenarios (a, b, and c). Sample sizes are so large that stochastic effects can be excluded (1000 observations). Effects of the ML models were inferred using average conditional effects. Row a) shows results for simulations with uncorrelated predictors with the true effect sizes. Row b) shows the results for simulations with X~1~ and X~2~ being strongly correlated (Pearson correlation factor = 0.9) but only X~1~ has an effect on y (mediator) and row c) shows the results for X~1~ and X~2~ being strongly correlated (Pearson correlation factor = 0.9) with X~1~ and X~2~ having effects on Y (confounder scenario)."
#| fig-width: 14
#| fig-height: 10
#| warning: false
#| message: false

parser = function(true, bias, pos = 1) {
  if(pos == 1) { 
    yp = 1.25
    xp = 0.15
  }
  if(pos == 3) {
    yp = 1.63
    xp = -0.05
  }
  if(pos == 2) {
    yp = 0.37
    xp = -0.05
  }
  bb = round(bias, 2)
  if(bb > 0) { 
    symb = "+" 
    if(abs(bb) > 0.001) text(x = xp + 0.280, y = yp+0.01, pos = 4, symb, cex = 1.3, col = "#DD5353", font = 2)
  } else { 
    symb = "-"
      if(abs(bb) > 0.001) text(x = xp + 0.29, y = yp, pos = 4, symb, cex = 1.3, col = "#DD5353", font = 2)
    }
  bb = abs(bb)
   text(x = xp, y = yp, pos = 4,label = format(true, nsmall = 2), cex = 1.3)

  if(bb> 0.001) text(x = xp+ 0.35, y = yp, pos = 4, label = format(bb, nsmall = 2), cex = 1.3, col = "#DD5353", font = 1)
}

par(mfcol = c(3,7), mar = c(5,0.5, 2, 1.4), oma = c(1, 2, 2, 1))
labs =  c("LM","RT LC", "RT HC",  "Linear Booster", "Tree Booster LC", "Tree Booster HC")
cex_fac = 1.3
minArrow = function(x) sapply(x, function(xx) max(c(0.1, xx)))

true_effs = matrix(c(
  1, 0.0, 1,
  1, 0.0, 1,
  1, 0.5, 1
), 3, 3, byrow = TRUE)


vertex_col_p = "#86A3B8"
vertex_col_y = "#E8D2A6"
vertex_col_frame = "#181823"
vertex_frame_width = 2.0

# A simulation
g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"),  
            directed=TRUE ) 
#layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE)
eqarrowPlot(g1, matrix(c(1,1,
                         0,1,
                         0,0,
                         0,2), nrow = 4L, 2L, byrow = TRUE) ,
            cols = c(addA(rep(vertex_col_p, 1), 1.0), 
                     vertex_col_y, 
                     addA(rep(vertex_col_p, 1), 1.0),
                     addA(rep(vertex_col_p, 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.1, 1.0)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("",3),
            edge.label.cex = 1.4,
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,
            vertex.frame.width = vertex_frame_width,
            edge.colors = rep("#B0A8B9", 3))
  text(letters[1], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
  text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.0, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)

# B simulation
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
            cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 2), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.1, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,
            vertex.frame.width = vertex_frame_width,            
            edge.arrow.mode = c(rep(">", 3), "-"), 
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
text(letters[2], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.0, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)

# C simulation
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
                cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.5, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            vertex.frame.width = vertex_frame_width,
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,            
            edge.arrow.mode = c(rep(">", 3), "-"), 
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
text(letters[2], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.5, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)
points(x = 0, y = -0.55, col = "grey", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.55, label = "True effect", xpd = NA, pos = 4, cex = 1.4)
points(x = 0, y = -0.75, col = "#ffab02", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.75, label = "Correlation", xpd = NA, pos = 4, cex = 1.4)



for(i in 1:6) {
  counter = 1
  for(j in 1:3) {

    tmp = plot_results[[j]]
    edges = round(tmp[i,], 5)
    bias = edges[c(1, 2, 5)] - true_effs[j,]
    g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"),  
                directed=TRUE ) 
    layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE)
    eqarrowPlot(g1, matrix(c(1,1,
                             0,1,
                             0,0.0,
                             0,2), nrow = 4L, 2L, byrow = TRUE) ,
                cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 1), 1.0)),
                edge.arrow.size=minArrow(abs(-true_effs[j,] - bias)),
                edge.width=abs(-true_effs[j,] - bias)*cex_fac,
                edge.label = rep("",3),
                edge.label.cex = 1.4,
                vertex.frame.color=vertex_col_frame,
                vertex.label.color= vertex_col_frame,
                vertex.frame.width = vertex_frame_width,                  
                edge.colors = ifelse(abs(bias) < 0.01, "#B0A8B9", "#DD5353"))
    parser(true_effs[j, 1], bias[1], pos = 1)
    parser(true_effs[j, 2], bias[2], pos = 2)
    parser(true_effs[j, 3], bias[3], pos = 3)
    text(labs[i], x = 0, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
    if(i == 1) {
      text(letters[counter], cex = 1.9, x = -2.2, y = 2.5, xpd = NA, font = 2)
      counter = counter + 1
    }

  }
  if(i == 3) {
    points(x = 0-1, y = -1.1*0.5, col = "#DD5353", xpd = NA, pch = 15, cex = 1.8)
    text(x = 0.1-1, y = -1.1*0.5, label = "Bias", xpd = NA, pos = 4, cex = 1.4)
  }
}
```

We found that the regression tree (RT) is unable to estimate unbiased effects (Fig. S3), regardless of the presence or absence of collinearity or the complexity of the RT (depth of the regression trees). Without collinearity, effects in regression trees were biased toward zero, less so with higher complexity (Fig. S3). With collinearity, there was a small spillover effect for the RT with high complexity (Fig. S3b) to the collinear zero effect (X~2~), similar to an l2 regularization. When the collinear predictor (X~2~) had an effect (Fig. S3c), we found a stronger absolute bias for the smaller of the two collinear effects (X~2~), confirming our expectation that RTs show a greedy effect. This greedy behavior was particularly strong for the low complexity RT (Fig. S3c).

To answer the question of how boosting affects the greediness and spillover effects of RT, we first investigated the behavior of a linear booster because of the well-known behavior of OLS under collinearity. And indeed, we found that the linear booster was unbiased in all three scenarios (compare LM and linear booster in Fig. S3), showing that boosting itself can produce unbiased effects.

Now, comparing the vanilla BRTs with low and high complexity (depth of individual trees) with the linear booster and the RTs, we found similar biases as for the RTs, in terms of spillover with a collinear zero effect and the greediness effect in the presence of a weaker collinear effect (Fig. S3).

### Understanding boosting

Intuitive boosting shouldn't work because it's basically a regression of residuals. That is, and in the case of collinearity, the stronger of two collinear predictors in the first model would absorb the effect of the weaker second predictor that, for example, causes the omitted variable bias (the effect of the missing confounder is absorbed by the collinear effect).

```{r}
#| warning: false
#| message: false
set.seed(42)
sim = function() simulate(r = 0.9, effs = c(1, 0.5, 0, 0, 1, seq(-0.2, 0.2, length.out = 10)),n = 500)
data = sim()
data[,-1] = scale(data[,-1])

m = get_boosting_model(x = data[,-1], y = data[,1], n_trees = 100, booster = "linear")

eff_change =
  sapply(1:100, function(i) {
    m$N = i
    eff = diag(marginalEffects(m, data = data.frame(data)[,-1], interactions = FALSE, max_indices = 5)$mean)
    return(eff)
  })

eff_relative =
  sapply(1:100, function(i) {
    tmp = m
    tmp$model = list(m$model[[i]])
    tmp$N = 1
    eff = diag(marginalEffects(tmp, data = data.frame(data)[,-1], interactions = FALSE, max_indices = 5)$mean)
    return(eff)
  })
```

```{r}
#| label: fig-Fig_S4
#| fig-cap: "Changes of effects within boosting. (A) shows the total effect of ensemble (linear booster) until the n-th ensemble member. (B) shows the effects of the n-th ensemble member. X1 and X2 were correlated (Pearson correlationf factor = 0.9)."
#| fig-width: 9
#| fig-height: 4.5
#| warning: false
#| message: false

cols = c("#0000FF", "black", "#FF0000")
par(mfrow = c(1, 2), mar = c(4, 4, 2, 2))
matplot(t(eff_change)[, c(1, 2, 5)], type = "l", lty = 1, las = 1, 
        xlab = "Number of boosters", 
        ylab = "Total effect size",
        lwd = 2,
        col = cols
        )
legend("topright", lty = 1, col = cols, legend = c("\U03B2\U2081 (true effect = 1.0)",
                                                   "\U03B2\U2082 (true effect = 0.5)",
                                                   "\U03B2\U2085 (true effect = 1.0)"), bty = "n")
text(x = 0, y = 1.55, pos = 2, label = "a", xpd = NA, font = 2, cex = 1.2)
matplot(t(eff_relative)[, c(1, 2, 5)], type = "p", 
        lty = 1, las = 1, xlab = "n-th booster", ylab = "Effect of n-th booster", pch = 16,col = cols)
text(x = 0, y = 1.55, pos = 2, label = "b", xpd = NA, font = 2, cex = 1.2)
legend("topright", lty = 1, col = cols, legend = c("\U03B2\U2081 (true effect = 1.0)",
                                                   "\U03B2\U2082 (true effect = 0.5)",
                                                   "\U03B2\U2085 (true effect = 1.0)"), bty = "n")

```

Looking at the development of the total effect within a linear booster model (Fig. S4a), we found that the first members of the ensemble absorb the effect of the collinear effect ($\beta_1$ absorbed $\beta_2$, Fig. S4a), but as members are added to the ensemble, the collinear effect $\beta_2$ slowly recovers the effect of the stronger collinear effect until both are at their correct effect estimate (Fig. S4a). This retrieval works by reversing the sign of each member's effect, so that $\beta_1$, which initially has an effect of 1.5 (because it absorbed the effect of $\beta_2$), has small negative effects in subsequent trees, while $\beta_2$, which is initially estimated at 0, has small positive effects (Fig. S4b).


## Proof of concept - Additional results

### Addtional scenarios

To better understand the ability of ML algorithms in learning unbiased effects, we tested additional scenarios (Fig. S5, first column). 
```{r}
#| echo: false

files =        c("collinearity_0.5.RDS", 
                 "collinearity_0.90.RDS", 
                 "collinearity_0.99.RDS", 
                 "effects.RDS", 
                 "no_effects.RDS", 
                 "confounder_unequal.RDS", 
                 "confounder.RDS")

Results = 
  lapply(files, function(f) {
    confounder = readRDS(paste0("results/",f))
    Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:length(confounder), function(i) confounder[[i]][[j]][[1]] ), along = 0L), 2, mean))))
    colnames(Result) = LETTERS[1:5]
    rownames(Result) = c("LM", "RF", "BRT", "NN", "Dropout", "l1", "l2", "l1l2")
    return(Result)
  })
names(Results) = unlist(strsplit(files, ".RDS", TRUE))


Results_rmse = 
  lapply(files, function(f) {
    confounder = readRDS(paste0("results/",f))
    Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:length(confounder), function(i) confounder[[i]][[j]][[2]] ), along = 0L), 2, mean))))
    colnames(Result) = "RMSE"
    rownames(Result) = c("LM", "RF", "BRT", "NN", "Dropout","l1", "l2", "l1l2")
    return(Result)
  })
names(Results_rmse) = unlist(strsplit(files, ".RDS", TRUE))

RMSEs = round(do.call(cbind, Results_rmse), 3)
colnames(RMSEs) = unlist(strsplit(files, ".RDS", TRUE))

Results_sd = 
  lapply(files, function(f) {
    confounder = readRDS(paste0("results/",f))
    Result = do.call(rbind, lapply(1:8, function(j) (apply(abind::abind(lapply(1:length(confounder), function(i) confounder[[i]][[j]][[1]] ), along = 0L), 2, sd))))
    colnames(Result) = LETTERS[1:5]
    rownames(Result) = c("LM", "RF", "BRT", "NN","Dropout", "l1", "l2", "l1l2")
    return(Result)
  })
names(Results_sd) = unlist(strsplit(files, ".RDS", TRUE))



```

```{r}
#| label: fig-Fig_S5
#| fig-cap: "Bias on effect estimates for different ML algorithms in trhee different simulated causal simulations (a, b, and c). Sample sizes are so large that stochastic effects can be excluded (1000 observations). Effects of the ML models were inferred using average conditional effects. Row a) shows the results for simulations with X~1~ and X~2~ being strongly correlated (Pearson correlation factor = 0.99) but only X~1~ has an effect on y. Row b) shows results for simulations with with predictors (Pearson correlation factor = 0.5) with effect sizes (X~1~: 1.0, X~2~: 0.5, X~3~: 1.0) and row c) shows results for simulations with with predictors (Pearson correlation factor = 0.5) with effect sizes (X~1~: 1.0, X~2~: -0.5, X~3~: 1.0) "
#| fig-width: 12
#| fig-height: 10.5
#| warning: false
#| message: false

parser = function(true, bias, pos = 1) {
  if(pos == 1) { 
    yp = 1.25
    xp = 0.15
  }
  if(pos == 3) {
    yp = 1.63
    xp = -0.05
  }
  if(pos == 2) {
    yp = 0.37
    xp = -0.05
  }
  
  bb = round(bias, 2)
  if(bb > 0) { 
    symb = "+" 
    if(abs(bb) > 0.001) text(x = xp + 0.280, y = yp+0.01, pos = 4, symb, cex = 1.3, col = "#DD5353", font = 2)
  } else { 
    symb = "-"
      if(abs(bb) > 0.001) text(x = xp + 0.29, y = yp, pos = 4, symb, cex = 1.3, col = "#DD5353", font = 2)
    }
  bb = abs(bb)
   text(x = xp, y = yp, pos = 4,label = format(true, nsmall = 2), cex = 1.3)

  if(bb> 0.001) text(x = xp+ 0.35, y = yp, pos = 4, label = format(bb, nsmall = 2), cex = 1.3, col = "#DD5353", font = 1)
}



sc = c("collinearity_0.99", "confounder","confounder_unequal")

#cairo_pdf("plots/Fig_2222.pdf", width = 12, height = 10.5)

par(mfcol = c(3,6), mar = c(5,0.5, 2, 1.4), oma = c(1, 2, 2, 1))
labs =  c("LM","RF",  "BRT", "NN","Dropout", "l1", "l2", "Elastic-net")
cex_fac = 1.3
minArrow = function(x) sapply(x, function(xx) max(c(0.1, xx)))

true_effs = matrix(c(
  1, 0.0, 1,
  1, 0.5, 1,
  1, -0.5, 1
), 3, 3, byrow = TRUE)

# A simulation
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
            cols = c(addA(rep(vertex_col_p, 1), 1.0), 
                     vertex_col_y, 
                     addA(rep(vertex_col_p, 1), 1.0),
                     addA(rep(vertex_col_p, 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.1, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            edge.arrow.mode = c(rep(">", 3), "-"), 
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,
            vertex.frame.width = vertex_frame_width,            
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
text(letters[1], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.0, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.99", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)


# B 
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
            cols = c(addA(rep(vertex_col_p, 1), 1.0), 
                     vertex_col_y, 
                     addA(rep(vertex_col_p, 1), 1.0),
                     addA(rep(vertex_col_p, 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.5, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.5, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,
            vertex.frame.width = vertex_frame_width,            
            edge.arrow.mode = c(rep(">", 3), "-"), 
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
text(letters[2], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.5, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)


# C simulation

g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
            cols = c(addA(rep(vertex_col_p, 1), 1.0), 
                     vertex_col_y, 
                     addA(rep(vertex_col_p, 1), 1.0),
                     addA(rep(vertex_col_p, 1), 1.0)),            
            edge.arrow.size=minArrow(c(1.00, 0.5, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.5, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,
            vertex.frame.width = vertex_frame_width,            
            edge.arrow.mode = c(rep(">", 3), "-"), 
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
text(letters[3], cex = 1.9, x = -1.6, y = 1.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(-0.5, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)




points(x = 0, y = -0.55, col = "grey", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.55, label = "True effect", xpd = NA, pos = 4, cex = 1.4)
points(x = 0, y = -0.75, col = "#ffab02", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.75, label = "Correlation", xpd = NA, pos = 4, cex = 1.4)
for(i in c(1, 2, 3, 4, 8)) {
  counter = 1
  for(j in c(1, 2, 3)) {

    tmp = Results[[sc[j]]]
    sd = Results_sd[[sc[j]]][i,]
    edges = round(tmp[i,], 5)
    bias = edges[c(1, 2, 5)] - true_effs[j,]
    g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"),  
                directed=TRUE ) 
    layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE)
    eqarrowPlot(g1, matrix(c(1,1,
                             0,1,
                             0,0,
                             0,2), nrow = 4L, 2L, byrow = TRUE) ,
              cols = c(addA(rep(vertex_col_p, 1), 1.0), 
                     vertex_col_y, 
                     addA(rep(vertex_col_p, 1), 1.0),
                     addA(rep(vertex_col_p, 1), 1.0)),
                edge.arrow.size=minArrow(abs(-true_effs[j,] - bias)),#abs(edges[c(1, 2, 5)]), 
                edge.width=abs(-true_effs[j,] - bias)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
                edge.label = rep("",3),
                edge.label.cex = 1.4,
                vertex.frame.color=vertex_col_frame,
                vertex.label.color= vertex_col_frame,
                vertex.frame.width = vertex_frame_width,                
                edge.colors = ifelse(abs(bias) < 0.01, "#B0A8B9", "#DD5353"))
    parser(true_effs[j, 1], bias[1], pos = 1)
    parser(true_effs[j, 2], bias[2], pos = 2)
    parser(true_effs[j, 3], bias[3], pos = 3)
    text(labs[i], x = 0, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
    if(i == 1) {
      text(letters[counter], cex = 1.9, x = -2.2, y = 2.5, xpd = NA, font = 2)
      counter = counter + 1
    }

  }
  if(i == 3) {
    points(x = 0-1, y = -1.1*0.5, col = "#DD5353", xpd = NA, pch = 15, cex = 1.8)
    text(x = 0.1-1, y = -1.1*0.5, label = "Bias", xpd = NA, pos = 4, cex = 1.4)
  }
}
#dev.off()

```


We found that NN cannot separate extreme collinear effects as the OLS (Fig. S5a) which, however, may improve with additional observations. 

### Additonal models 

To understand the different effects of regularization in NN (dropout), LASSO regression, and Ridge regression, we tested these models on our theoretical scenarios (Fig. S6, first column). 


```{r}
#| label: fig-Fig_S6
#| fig-cap: "Bias on effect estimates for different ML algorithms in two different simulated causal simulations (a and b). Sample sizes are so large that stochastic effects can be excluded. Effects of the ML models were inferred using average conditional effects. Row a) shows results for simulations with with predictors (Pearson correlation factor = 0.5) with effect sizes (X~1~: 1.0, X~2~: -0.5, X~3~: 1.0). Row b) shows the results for simulations with X~1~ and X~2~ being strongly correlated (Pearson correlation factor = 0.99) but only X~1~ has an effect on y. "
#| fig-width: 11
#| fig-height: 14
#| warning: false
#| message: false

parser = function(true, bias, pos = 1) {
  if(pos == 1) { 
    yp = 1.25
    xp = 0.15
  }
  if(pos == 3) {
    yp = 1.63
    xp = -0.05
  }
  if(pos == 2) {
    yp = 0.37
    xp = -0.05
  }
  
  bb = round(bias, 2)
  if(bb > 0) { 
    symb = "+" 
    if(abs(bb) > 0.001) text(x = xp + 0.280, y = yp+0.01, pos = 4, symb, cex = 1.3, col = "#DD5353", font = 2)
  } else { 
    symb = "-"
      if(abs(bb) > 0.001) text(x = xp + 0.29, y = yp, pos = 4, symb, cex = 1.3, col = "#DD5353", font = 2)
    }
  bb = abs(bb)
   text(x = xp, y = yp, pos = 4,label = format(true, nsmall = 2), cex = 1.3)

  if(bb> 0.001) text(x = xp+ 0.35, y = yp, pos = 4, label = format(bb, nsmall = 2), cex = 1.3, col = "#DD5353", font = 1)
}



sc = c("effects", "collinearity_0.90", "confounder", "confounder_unequal" )

#cairo_pdf("plots/Fig_2222.pdf", width = 11, height = 14)

par(mfcol = c(4,4), mar = c(5,0.5, 2, 1.4), oma = c(1, 2, 2, 1)+1)
labs =  c("LM","RF",  "BRT", "NN","Dropout", "l1", "l2", "Elastic-net")
cex_fac = 1.3
minArrow = function(x) sapply(x, function(xx) max(c(0.1, xx)))

true_effs = matrix(c(
  1, 0.0, 1,
  1, 0.0, 1,
  1, 0.5, 1,
  1, -0.5, 1
), 4, 3, byrow = TRUE)


# A simulation
g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                         0,1,
                         0,0,
                         0,2), nrow = 4L, 2L, byrow = TRUE) ,
                cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.1, 1.0)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("",3),
            edge.label.cex = 1.4,
            vertex.frame.width = vertex_frame_width,
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,            
            edge.colors = rep("#B0A8B9", 3))
  text(letters[1], cex = 1.9, x = -0.7, y = 2.5, xpd = NA, font = 2)
  text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.0, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)


# B simulation
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
                cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.1, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.1, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            vertex.frame.width = vertex_frame_width,
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,            
            edge.arrow.mode = c(rep(">", 3), "-"), 
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
  text(letters[2], cex = 1.9, x = -0.7, y = 2.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.0, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)


# C simulation
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
                cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.5, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.5, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            vertex.frame.width = vertex_frame_width,
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,            
            edge.arrow.mode = c(rep(">", 3), "-"), 
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
  text(letters[3], cex = 1.9, x = -0.7, y = 2.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(0.5, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)


# D simulation
g1 <- graph(c("x\U2081", "y", "x\U2082","y", "x\U2083", "y", "x\U2081", "x\U2082"),  
            directed=TRUE ) 
eqarrowPlot(g1, matrix(c(1,1,
                       0,1,
                       0,0,
                       0,2), nrow = 4L, 2L, byrow = TRUE) , 
                cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 1), 1.0)),
            edge.arrow.size=minArrow(c(1.00, 0.5, 1.0, 0.9)),#abs(edges[c(1, 2, 5)]), 
            edge.width=c(1.00, 0.5, 1.0, 0.5)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
            edge.label = rep("", 3), 
            edge.label.cex = 1.4, 
            vertex.frame.width = vertex_frame_width,
            vertex.frame.color=vertex_col_frame,
            vertex.label.color= vertex_col_frame,            
            edge.arrow.mode = c(rep(">", 3), "-"), 
            edge.colors = c(rep("#B0A8B9", 1),"#B0A8B9","#B0A8B9", "#ffab02"))
  text(letters[4], cex = 1.9, x = -0.7, y = 2.5, xpd = NA, font = 2)
text("Simulation", x = 0.3, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
parser(1.00, 0.0000, pos = 1)
parser(-0.5, 0.0000, pos = 2)
parser(1.00, 0.0000, pos = 3)  
text("0.90", cex = 1.3, x = 0.74, y = 0.5, xpd = NA, font = 1, col = "#ff9902")
segments(x0 = 1.4, x1 = 1.4, y0 = -0.5, y1 = 2.5, xpd = NA)



points(x = 0, y = -0.55, col = "grey", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.55, label = "True effect", xpd = NA, pos = 4, cex = 1.4)
points(x = 0, y = -0.75, col = "#ffab02", xpd = NA, pch = 15, cex = 1.8)
text(x = 0.1, y = -0.75, label = "Correlation", xpd = NA, pos = 4, cex = 1.4)
for(i in c(5, 6, 7)) {
  counter = 1
  for(j in c(1, 2, 3, 4)) {

    tmp = Results[[sc[j]]]
    sd = Results_sd[[sc[j]]][i,]
    edges = round(tmp[i,], 5)
    bias = edges[c(1, 2, 5)] - true_effs[j,]
    g1 = graph(c("x\U2081", "y", "x\U2082", "y", "x\U2083", "y"),  
                directed=TRUE ) 
    layout_as_tree(g1, root = "y", circular = TRUE, flip.y = TRUE)
    eqarrowPlot(g1, matrix(c(1,1,
                             0,1,
                             0,0,
                             0,2), nrow = 4L, 2L, byrow = TRUE) ,
                cols = c(addA(rep(vertex_col_p, 1), 1.0), vertex_col_y, addA(rep(vertex_col_p, 1), 1.0), addA(rep(vertex_col_p, 1), 1.0)),
                edge.arrow.size=minArrow(abs(-true_effs[j,] - bias)),#abs(edges[c(1, 2, 5)]), 
                edge.width=abs(-true_effs[j,] - bias)*cex_fac,#abs(edges[c(1, 2, 5)])*cex_fac,
                edge.label = rep("",3),
                edge.label.cex = 1.4,
                vertex.frame.width = vertex_frame_width,
                vertex.frame.color=vertex_col_frame,
                vertex.label.color= vertex_col_frame,                
                edge.colors = ifelse(abs(bias) < 0.01, "#B0A8B9", "#DD5353"))
    parser(true_effs[j, 1], bias[1], pos = 1)
    parser(true_effs[j, 2], bias[2], pos = 2)
    parser(true_effs[j, 3], bias[3], pos = 3)
    text(labs[i], x = 0, y = 2.3, xpd = NA, cex = 1.4, pos = 3)
    if(i == 1) {
      text(letters[counter], cex = 1.9, x = -2.2, y = 2.5, xpd = NA, font = 2)
      counter = counter + 1
    }

  }
  if(i == 3) {
    points(x = 0-1, y = -1.1*0.5, col = "#DD5353", xpd = NA, pch = 15, cex = 1.8)
    text(x = 0.1-1, y = -1.1*0.5, label = "Bias", xpd = NA, pos = 4, cex = 1.4)
  }
}

#dev.off()
```


Dropout has an negative effect on the ability to separate collinear effects in NN (Fig. S6) while also LASSO and Ridge (as expected) affect negatively the ability to separate collinear effects (Fig. S6).


## Hyperparameter tuning

We performed a hyperparameter search to check if and how hyperparameters influence differently or equally effect estimates and the prediction error, so does a model tune after the prediction error has biased effects? For that, we created simulation scenarios with 50, 100, 600, and 2000 observations and 100 predictors with effects ($beta_i, i = 1,...,100$) $\beta_1 = 1.0$, and $\beta_2$ to $\beta_3$ were equally spaced between 0.0 to 1.0 so that $\beta_2 = 0.0$ and $\beta_{100} = 1.0$.

Predictors were sampled from a multivariate normal distribution and all predictors were randomly correlated (Variance-covariance matrix $\Sigma$ was sampled from a LKJ-distribution with $\eta = 2.0$.

1,000 combinations of hyper-parameters were randomly drawn (Table S1). For each draw of hyperparameters, the data simulation and model fitting was repeated 20 times. Effect sizes of X~1~ and X~2~ were recorded (for each hyperparameter combination and for each reptition). Moreover, bias, variance, and mean square error (MSE) were recorded for the predictions on a holdout of the same size as the training data.

| Algorithm               | Hyper-parameter       | Range                                             |
|-------------------|-------------------|----------------------------------|
| Neural Network          | activation function   | \[relu, leaky_relu, tanh, selu, elu, celu, gelu\] |
|                         | depth                 | \[1, 8\]                                          |
|                         | width                 | \[2, 50\]                                         |
|                         | batch size (sgd)      | \[1, 100\] in percent                             |
|                         | lambda                | \[2.65e-05, 0.16\]                                |
|                         | alpha                 | \[0, 1.0\]                                        |
| Boosted Regression Tree | eta                   | \[0.01, 0.4\]                                     |
|                         | max depth             | \[2, 25\]                                         |
|                         | subsample             | \[0.5, 1\]                                        |
|                         | max tree              | \[30, 125\]                                       |
|                         | lambda                | \[1, 20\]                                         |
| Random Forest           | mtry                  | \[0, 1\] in percent                               |
|                         | min node size         | \[2, 70\]                                         |
|                         | max depth             | \[2, 50\]                                         |
|                         | regularization factor | \[0, 1\]                                          |
| Elastic net             | alpha                 | \[0, 1.0\]                                        |
|                         | lambda                | \[0, 1.0\]                                        |

: Overview over hyper-parameters for Neural Network, Boosted Regression Tree, and Random Forest {#tbl-Hyper}

### Results hyperparameter tuning

As described in the main text, we analyzed the effects of the hyperparameters on the different errors using GAMs and variable importance of random forest (Fig. S7, S8, S9). 

```{r}
#| label: fig-Fig_S7
#| fig-cap: "Results of hyperparameter tuning for Neural Networks (NN), Boosted Regression Trees (BRT), Random Forests (RF), and Elastic Net (EN) for 50 observations with 100 predictors. The influence of the hyperparameters on effect $\\hat{\\beta}_1$ (bias, variance, and MSE)(true simulated effect $\\beta_1 = 1.0$  ) and the predictions, $\\hat{y}$ of the model (bias, variance, and MSE) were estimated by a multivariate generalized additive model (GAM). Categorical hyperparameters (activation function in NN) were estimated as fixed effects. The responses (bias, variance, MSE) were centered so that the categorical hyperparameters correspond to the intercepts. The variable importance of the hyperparameters was estimated by a random forest with the MSE of the effect $\\hat{\\beta}_1$ (first plot) or the prediction $\\hat{y}$ (second plot) as the response. Red dots correspond to the best predicted set of hyperparameters (based on a random forest), in the first plot for the minimum MSE of the effect $\\hat{\\beta}_1$ and in the second plot for the minimum MSE of the predictions $\\hat{y}$."
#| fig-width: 9
#| fig-height: 10
#| warning: false
#| message: false

results_50 = readRDS("results/hyper_parameter_aggregation_50.RDS")
data = do.call(rbind, lapply(results_50, function(r) r$data))

labels = c("CELU",
           "ELU",
           "GELU",
           "Leaky ReLU",
           "ReLU",
           "SELU",
           "tanh",
           "batch size",
           "depth",
           "width",
           "alpha",
           "lambda",
           "eta",
           "max depth",
           "subsample",
           "max tree",
           "mtry",
           "min node size",
           "max depth",
           "regularization factor")
names(labels) = c("activationscelu",
                  "activationselu",
                  "activationsgelu",
                  "activationsleaky_relu",
                  "activationsrelu",
                  "activationsselu",
                  "activationstanh",
                  "sgd",
                  "depth", 
                  "width",
                  "alpha", 
                  "lambda",
                  "eta",
                  "max_depth",
                  "subsample",
                  "max_tree",
                  "mtry",
                  "min.node.size",
                  "max.depth",
                  "regularization.factor")
tck = 0.015
mgp = 0.07
eff_range = list(eff_range2 = c(-0.5, 0.5),eff_range1 = c(-0.04, 0.04))
vi_range = list(c(0, 0.04), c(0, 2.5))
cols = (c("#1C1C1BFF","#CC4A7EFF"))
plot_tuning(data = data, results = results_50, eff_range = eff_range, vi_range = vi_range, line_col = cols)
axis(3, at = scales::rescale(c(-0.25, 0.0, 0.25), to = c(0.02, 0.28), from = eff_range[[1]]), labels = c(-0.25, 0.0, 0.25), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(-0.02, 0.0, 0.02), to = c(0.02, 0.28), from = eff_range[[2]])+0.5, labels = c(-0.02, 0.0, 0.02), tck = tck, mgp = c(3, mgp, 0))

axis(3, at = scales::rescale(c(0, log10(0.03+1), log10(0.08+1)), to = c(0.3, 0.5), from = vi_range[[1]]),  
     labels = c(0, 0.03, 0.08), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(0, log10(10+1), log10(130+1)), to = c(0.3, 0.5), from = vi_range[[2]])+0.5, labels = c(0, 10, 130), tck = tck, mgp = c(3, mgp, 0))

```

```{r}
#| label: fig-Fig_S8
#| fig-cap: "Results of hyperparameter tuning for Neural Networks (NN), Boosted Regression Trees (BRT), Random Forests (RF), and Elastic Net (EN) for 600 observations with 100 predictors. The influence of the hyperparameters on effect $\\hat{\\beta}_1$ (bias, variance, and MSE)(true simulated effect $\\beta_1 = 1.0$  ) and the predictions, $\\hat{y}$ of the model (bias, variance, and MSE) were estimated by a multivariate generalized additive model (GAM). Categorical hyperparameters (activation function in NN) were estimated as fixed effects. The responses (bias, variance, MSE) were centered so that the categorical hyperparameters correspond to the intercepts. The variable importance of the hyperparameters was estimated by a random forest with the MSE of the effect $\\hat{\\beta}_1$ (first plot) or the prediction $\\hat{y}$ (second plot) as the response. Red dots correspond to the best predicted set of hyperparameters (based on a random forest), in the first plot for the minimum MSE of the effect $\\hat{\\beta}_1$ and in the second plot for the minimum MSE of the predictions $\\hat{y}$."
#| fig-width: 9
#| fig-height: 10
#| warning: false
#| message: false

results_600 = readRDS("results/hyper_parameter_aggregation_600.RDS")
data = do.call(rbind, lapply(results_600, function(r) r$data))

labels = c("CELU",
           "ELU",
           "GELU",
           "Leaky ReLU",
           "ReLU",
           "SELU",
           "tanh",
           "batch size",
           "depth",
           "width",
           "alpha",
           "lambda",
           "eta",
           "max depth",
           "subsample",
           "max tree",
           "mtry",
           "min node size",
           "max depth",
           "regularization factor")
names(labels) = c("activationscelu",
                  "activationselu",
                  "activationsgelu",
                  "activationsleaky_relu",
                  "activationsrelu",
                  "activationsselu",
                  "activationstanh",
                  "sgd",
                  "depth", 
                  "width",
                  "alpha", 
                  "lambda",
                  "eta",
                  "max_depth",
                  "subsample",
                  "max_tree",
                  "mtry",
                  "min.node.size",
                  "max.depth",
                  "regularization.factor")

eff_range = list(eff_range2 = c(-0.5, 0.5),eff_range1 = c(-0.04, 0.04))
vi_range = list(c(0, 0.10), c(0, 2.5))
cols = (c("#1C1C1BFF","#CC4A7EFF"))
plot_tuning(data = data, results = results_600, eff_range = eff_range, vi_range = vi_range, line_col = cols)
axis(3, at = scales::rescale(c(-0.25, 0.0, 0.25), to = c(0.02, 0.28), from = eff_range[[1]]), labels = c(-0.25, 0.0, 0.25), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(-0.02, 0.0, 0.02), to = c(0.02, 0.28), from = eff_range[[2]])+0.5, labels = c(-0.02, 0.0, 0.02), tck = tck, mgp = c(3, mgp, 0))

axis(3, at = scales::rescale(c(0, log10(0.05+1), log10(0.14+1)), to = c(0.3, 0.5), from = vi_range[[1]]),  
     labels = c(0, 0.05, 0.14), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(0, log10(10+1), log10(130+1)), to = c(0.3, 0.5), from = vi_range[[2]])+0.5, labels = c(0, 10, 130), tck = tck, mgp = c(3, mgp, 0))

```

```{r}
#| label: fig-Fig_S9
#| fig-cap: "Results of hyperparameter tuning for Neural Networks (NN), Boosted Regression Trees (BRT), Random Forests (RF), and Elastic Net (EN) for 2000 observations with 100 predictors. The influence of the hyperparameters on effect $\\hat{\\beta}_1$ (bias, variance, and MSE)(true simulated effect $\\beta_1 = 1.0$  ) and the predictions, $\\hat{y}$ of the model (bias, variance, and MSE) were estimated by a multivariate generalized additive model (GAM). Categorical hyperparameters (activation function in NN) were estimated as fixed effects. The responses (bias, variance, MSE) were centered so that the categorical hyperparameters correspond to the intercepts. The variable importance of the hyperparameters was estimated by a random forest with the MSE of the effect $\\hat{\\beta}_1$ (first plot) or the prediction $\\hat{y}$ (second plot) as the response. Red dots correspond to the best predicted set of hyperparameters (based on a random forest), in the first plot for the minimum MSE of the effect $\\hat{\\beta}_1$ and in the second plot for the minimum MSE of the predictions $\\hat{y}$."
#| fig-width: 9
#| fig-height: 10
#| warning: false
#| message: false

results_2000 = readRDS("results/hyper_parameter_aggregation_2000.RDS")
data = do.call(rbind, lapply(results_2000, function(r) r$data))

labels = c("CELU",
           "ELU",
           "GELU",
           "Leaky ReLU",
           "ReLU",
           "SELU",
           "tanh",
           "batch size",
           "depth",
           "width",
           "alpha",
           "lambda",
           "eta",
           "max depth",
           "subsample",
           "max tree",
           "mtry",
           "min node size",
           "max depth",
           "regularization factor")
names(labels) = c("activationscelu",
                  "activationselu",
                  "activationsgelu",
                  "activationsleaky_relu",
                  "activationsrelu",
                  "activationsselu",
                  "activationstanh",
                  "sgd",
                  "depth", 
                  "width",
                  "alpha", 
                  "lambda",
                  "eta",
                  "max_depth",
                  "subsample",
                  "max_tree",
                  "mtry",
                  "min.node.size",
                  "max.depth",
                  "regularization.factor")

eff_range = list(eff_range2 = c(-0.5, 0.5),eff_range1 = c(-0.04, 0.04))
vi_range = list(c(0, 0.10), c(0, 2.5))
cols = (c("#1C1C1BFF","#CC4A7EFF"))
plot_tuning(data = data, results = results_2000, eff_range = eff_range, vi_range = vi_range, line_col = cols)
axis(3, at = scales::rescale(c(-0.25, 0.0, 0.25), to = c(0.02, 0.28), from = eff_range[[1]]), labels = c(-0.25, 0.0, 0.25), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(-0.02, 0.0, 0.02), to = c(0.02, 0.28), from = eff_range[[2]])+0.5, labels = c(-0.02, 0.0, 0.02), tck = tck, mgp = c(3, mgp, 0))

axis(3, at = scales::rescale(c(0, log10(0.05+1), log10(0.14+1)), to = c(0.3, 0.5), from = vi_range[[1]]),  
     labels = c(0, 0.05, 0.14), tck = tck, mgp = c(3, mgp, 0))
axis(3, at = scales::rescale(c(0, log10(10+1), log10(130+1)), to = c(0.3, 0.5), from = vi_range[[2]])+0.5, labels = c(0, 10, 130), tck = tck, mgp = c(3, mgp, 0))

```


### Optimal hyperparameters

The hyperparameters were chosen based on the lowest MSE for the predictive performance of the models (Table S2) and the lowest MSE for the effect ($\beta_1$) on X~1~ (Table S3). The selection of the best hyperparameters was done by first fitting a random forest (default parameters) with the MSE as response and the hyperparameters as predictors, and then using the set of hyperparameters that predicted the lowest MSE. 

```{r}
#| warning: false
#| message: false
results_100 = readRDS("results/hyper_parameter_aggregation_100.RDS")
#| echo: false
round_if_num = function(x) {
  if(any(is.numeric(x))) x = round(x, 3)
  return(x)
}
create_table = function(tmp1, tmp2, tmp3,tmp4, method = "NN") {
  resHyper = rbind(tmp1, tmp2, tmp3, tmp4)
  hyn = colnames(resHyper)
  paste0(
  sapply(1:ncol(resHyper), function(i) {
    if(i == 1) prefix = method
    else prefix = " "
  return(paste0("| ",prefix," | ", hyn[i], " | ", paste0(round_if_num(resHyper[,i]), collapse = " | "), " | \n"))
  } ), collapse = "")
}

input_eff = paste0(
"| Algorithm | Hyperparameter | n = 50 | n = 100 | n = 600 | n = 2000 |\n",
"|-----------|-----------|-----------|-----------|-----------|-----------|\n",
create_table(results_50[[1]]$hyper$eff[,1:6], results_100[[1]]$hyper$eff[,1:6], results_600[[1]]$hyper$eff[,1:6],results_2000[[1]]$hyper$eff[,1:6], "NN"),
create_table(results_50[[2]]$hyper$eff[,1:5], results_100[[2]]$hyper$eff[,1:5], results_600[[2]]$hyper$eff[,1:5],results_2000[[2]]$hyper$eff[,1:5], "BRT"),
create_table(results_50[[3]]$hyper$eff[,1:4], results_100[[3]]$hyper$eff[,1:4], results_600[[3]]$hyper$eff[,1:4],results_2000[[3]]$hyper$eff[,1:4], "RF"),
create_table(results_50[[4]]$hyper$eff[,1:2], results_100[[4]]$hyper$eff[,1:2], results_600[[4]]$hyper$eff[,1:2],results_2000[[4]]$hyper$eff[,1:2], "EN"))

input_pred = paste0(
"| Algorithm | Hyperparameter | n = 50 | n = 100 | n = 600 | n = 2000 |\n",
"|-----------|-----------|-----------|-----------|-----------|-----------|\n",
create_table(results_50[[1]]$hyper$pred[,1:6], results_100[[1]]$hyper$pred[,1:6], results_600[[1]]$hyper$pred[,1:6],results_2000[[1]]$hyper$pred[,1:6], "NN"),
create_table(results_50[[2]]$hyper$pred[,1:5], results_100[[2]]$hyper$pred[,1:5], results_600[[2]]$hyper$pred[,1:5],results_2000[[2]]$hyper$pred[,1:5], "BRT"),
create_table(results_50[[3]]$hyper$pred[,1:4], results_100[[3]]$hyper$pred[,1:4], results_600[[3]]$hyper$pred[,1:4],results_2000[[3]]$hyper$pred[,1:4], "RF"),
create_table(results_50[[4]]$hyper$pred[,1:2], results_100[[4]]$hyper$pred[,1:2], results_600[[4]]$hyper$pred[,1:2],results_2000[[4]]$hyper$pred[,1:2], "EN"))

```


`r input_pred`

: Best predicted set of hyperparameterfor ML algorithms (tuned after MSE of predictions) {#tbl-Hyper_selected_pred}

`r input_eff`

: Best predicted set of hyperparameterfor ML algorithms (tuned after MSE of effect X~1~) {#tbl-Hyper_selected_eff}

## Additional results for data-poor scenarios

### Prediction error of scenarios

Fig. S10 shows the MSE of the predictions on the holdouts for the different ML algorithms and different number of observations of the data-poor scenarios (see main text).

```{r}
#| warning: false
#| message: false



extract_results = function(path, N = "small", tuned = "pred") {

  effs_true = c(1.0, 0.0)
  algorithms = c("LM", "RF", "BRT", "NN", "EN")
  inter_low = readRDS(path)
  mse = do.call(rbind, lapply(1:5, function(i) {data.frame(tuned = tuned,N = N,algorithm = algorithms[i], mse = sapply(inter_low, function(r) r[[i]][3]))}))
  #mse_sd = sapply(1:5, function(i) {sd(sapply(inter_low, function(r) r[[i]][3]))})

  return((mse))
}

res_pred =  do.call(rbind, lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_MSE.RDS"), n, "pred")))
res_eff = do.call(rbind, lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_BIAS.RDS"), n, "eff")))

res = rbind(res_pred, res_eff)
res[(res$algorithm == "LM") & (res$N %in% c("small", "mid")),]$mse = NA

res = res %>% mutate(N = as.factor(N), algorithm = as.factor(algorithm))

res$algorithm = forcats::lvls_reorder(res$algorithm, c(3, 5, 1, 4, 2))
levels(res$N) = c("N = 600", "N = 100", "N = 50")
res$N = forcats::lvls_reorder(res$N, c(3, 2, 1))
```


```{r}
#| label: fig-Fig_S10
#| fig-cap: "Prediction error (mean square error, MSE) of data poor simulations with optimal hyperparameters either tuned after the best MSE of the effect size (red) or the best MSE of the prediction error (blue)."
#| fig-width: 7
#| fig-height: 6
#| warning: false
#| message: false


g1 =ggplot(data = res, aes(x = algorithm, y = mse, fill = tuned)) +
  geom_boxplot() +
  facet_grid(N~.) + 
  theme_bw() +
  xlab("Algorithm") +
  ylab("MSE")+
  theme(legend.position = c(0.1, 0.15)) +
  theme(strip.background =element_rect(fill="white"))
g1
```


## Data-poor scenarios without collinearity

### Bias and variance of effects

To assess the effect of collinearity on the data-poor simulations, we repeated the scenarios but without collinearity. $\Sigma$ which was used in the sampling process of the predictor matrix (multivariate normal distribution) was set to the identity matrix. While it is not ideal, we used the best hyperparameters (Table S3, Table S4) which were tuned for the collinear scenarios, for these scenarios


```{r}
#| echo: false

effs_true = c(1.0, 0.0)
extract_B = function(RI, exponent = 1) {
  Bias = apply(abind::abind(lapply(1:length(RI), function(j) t(sapply(1:5, function(i) RI[[j]][[i]][1:2]  - effs_true))), along = 0L), 2:3, mean)**exponent
  Bias_1 = apply(Bias[,1, drop=FALSE], 1, mean)
  Bias_0 = apply(Bias[,2, drop=FALSE], 1, mean)
  return(cbind(Bias_1, Bias_0)) #, Bias_Inter_1, Bias_Inter_0))
}

extract_V= function(RI) {
  Var = apply(abind::abind(lapply(1:length(RI), function(j) t(sapply(1:5, function(i) RI[[j]][[i]][1:2] ))), along = 0L), 2:3, var)
  Var_1 = apply(Var[,1, drop=FALSE], 1, mean)
  Var_0 = apply(Var[,2, drop=FALSE], 1, mean)
  return(cbind(Var_1, Var_0))  #, Var_Inter_1, Var_Inter_0))
}

extract_results = function(path, N = "small", tuned = "pred") {

  effs_true = c(1.0, 0.0)
  
  inter_low = readRDS(path)
  bias_low = extract_B(inter_low, exponent = 1)
  var_low = extract_V(inter_low)
  mse = sapply(1:5, function(i) {mean(sapply(inter_low, function(r) r[[i]][3]))})
  

  return(list(bias = bias_low, var = var_low, mse = mse))
}

res_pred =  lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_MSE_no_coll.RDS"), n, "pred"))
res_eff = lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_BIAS_no_coll.RDS"), n, "eff"))

```

```{r}
#| label: fig-Fig_S11
#| fig-width: 10
#| fig-height: 7
#| fig-cap: "Bias and variance of estimated effects in data-poor situations. N = 50, 100, and 600 observations of 100 uncorrelated predictors were simulated. True effects in the data generating model were $\\beta_1$=1.0, $\\beta_2$=0.0, and the other 98 effects were equally spaced between 0 and 1. Models were fitted to the simulated data (1000 replicates) with the optimal hyperparameters (except for LM, which doesnâ€™t have hyperparameters). Hyperparameters were selected based on the minimum MSE of ($\\hat{\\beta}_1$) (green) or the prediction error (based on $\\hat{y}$  ) (red). Bias and variance were calculated for $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$. Effects $\\hat{\\beta}_i$ for $i=1,â€¦,100$) were approximated using ACE."
#| warning: false


bias = res_pred[[1]]$bias[1, 1]
var = res_pred[[1]]$var[1, 1]
draw_stacked_bar = function(bias, var, xleft = 0.0, w = 0.15) {
  rect(xleft, 0, xleft+w, abs(bias), col = "#96c6ed" )
  rect(xleft, abs(bias), xleft+w, abs(bias)+var, col = "#e0acd5" )
}

methods2 = c("LM", "RF", "BRT", "NN", "Elastic-net")
methods2[-1] = paste0(methods2[-1], " tuned")
par(mfrow = c(3, 5), mar = c(1, 1, 1, 1)*0.5, oma = c(12, 4, 4, 4))
y_labels = c("N = 50", "N = 100", "N = 600")
for(j in 1:3) {
  for(i in 1:5) {
    plot(NULL, NULL, xlim = c(0, 1), ylim = c(0, 1), yaxt = "n", xaxt = "n", xaxs = "i", yaxs = "i", xlab = "", ylab = "")
    if(i == 1) axis(2, las = 2, at = seq(0.0, 0.8, length.out = 5), labels =  format(seq(0.0, 0.8, length.out = 5)))
    if( i > 1) {
      rect(0.5, 0, 1.0, 1.0, col = "#EDBD9660", border = NA)
      rect(0.0, 0, 0.5, 1.0, col = "#9BED9660", border = NA)

      draw_stacked_bar(xleft = 0.1, res_pred[[j]]$bias[i, 1], res_pred[[j]]$var[i, 1])
      draw_stacked_bar(xleft = 0.1+0.18, res_pred[[j]]$bias[i, 2], res_pred[[j]]$var[i, 2])
      draw_stacked_bar(xleft = 0.1+0.47, res_eff[[j]]$bias[i, 1], res_eff[[j]]$var[i, 1])
      draw_stacked_bar(xleft = 0.1+0.18+0.47, res_eff[[j]]$bias[i, 2], res_eff[[j]]$var[i, 2])
    } else {
      
      if( ((j %in% c(1, 2)) && (i == 1) )) {
        text(x = 0.5, y = 0.5, pos = 3, label = "NA", font = 2)
      } else {
        draw_stacked_bar(xleft = 0.325, res_pred[[j]]$bias[i, 1], res_pred[[j]]$var[i, 1])
        draw_stacked_bar(xleft = 0.325+0.18, res_pred[[j]]$bias[i, 2], res_pred[[j]]$var[i, 2])

        text(x = c(0.185, 0.185+0.18),y = -0.24, 
        labels = c("Bias+Variance \U03B2\U2081", "Bias+Variance \U03B2\U2082"), 
        srt = 45,
        xpd = NA, pos = 1)        
      }
      
    }
    if(j == 1) {
      rect(0, 1.0, 1.0, 1.15, xpd = NA, border = "black")
      text(0.5, y = 0.98, pos = 3, xpd = NA, label = methods2[i], cex = 1.3, font = 2)
    }
    if(i == 5) {
      rect(1, 0, 1.15, 1.0, xpd = NA, border = "black")
      text(y = 0.72, x = 1.01, pos = 4, xpd = NA, label = y_labels[j], cex = 1.3, font = 2, srt = -90)
    }
    if( (j == 3) && (i > 1) ){
      text(x = c(0.185, 0.185+0.18, c(0.185, 0.185+0.18)+0.47)-0.22,y = -0.24, 
           labels = c("Bias+Variance \U03B2\U2081", "Bias+Variance \U03B2\U2082", "Bias+Variance \U03B2\U2081", "Bias+Variance \U03B2\U2082"), 
           srt = 45,
           xpd = NA, pos = 1)
    }    
  }
}

points(pch = 15, x = rep(-1.0, 2), y = c(-0.7, -0.8), xpd = NA, col = c("#96c6ed","#e0acd5"), cex = 1.5)
text(x = rep(-1.0, 2)+0.01, y = c(-0.7, -0.8)-0.02, pos = 4, labels = c("Bias", "Variance"), xpd = NA)

points(pch = 15, x = rep(-0.2, 2), y = c(-0.7, -0.8), xpd = NA, col = c("#9BED96","#EDBD96"), cex = 1.5)
text(x = rep(-0.2, 2)+0.01, y = c(-0.7, -0.8)-0.02, pos = 4, labels = c("Tuned after MSE of predictions", "Tuned after MSE of \U03B2\U2081"), xpd = NA)


```

We found similar results as for data-poor scenarios with collinearity (Fig. S11). NN and elastic-net show the lowest errors and strongest increase in those errors with increasing number of observations (Fig. S11).

### Prediction error of scenarios

Fig. S12 shows the prediction errors for the ML algorithms for the data-poor simulations without collinearity. We found similar results as for the data-poor simulations with collinearity.

```{r}
#| warning: false
#| message: false

extract_results = function(path, N = "small", tuned = "pred") {

  effs_true = c(1.0, 0.0)
  algorithms = c("LM", "RF", "BRT", "NN", "EN")
  inter_low = readRDS(path)
  mse = do.call(rbind, lapply(1:5, function(i) {data.frame(tuned = tuned,N = N,algorithm = algorithms[i], mse = sapply(inter_low, function(r) r[[i]][3]))}))
  #mse_sd = sapply(1:5, function(i) {sd(sapply(inter_low, function(r) r[[i]][3]))})

  return((mse))
}

res_pred =  do.call(rbind, lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_MSE_no_coll.RDS"), n, "pred")))
res_eff = do.call(rbind, lapply(c("small", "mid", "big"), function(n) extract_results(paste0("results/data_poor_",n ,"_BIAS_no_coll.RDS"), n, "eff")))

res = rbind(res_pred, res_eff)
res[(res$algorithm == "LM") & (res$N %in% c("small", "mid")),]$mse = NA

res = res %>% mutate(N = as.factor(N), algorithm = as.factor(algorithm))

res$algorithm = forcats::lvls_reorder(res$algorithm, c(3, 5, 1, 4, 2))
levels(res$N) = c("N = 600", "N = 100", "N = 50")
res$N = forcats::lvls_reorder(res$N, c(3, 2, 1))
```


```{r}
#| label: fig-Fig_S12
#| fig-cap: "Prediction error (mean square error, MSE) of data poor simulations with optimal hyperparameters either tuned after the best MSE of the effect size (red) or the best MSE of the prediction error (blue)."
#| fig-width: 7
#| fig-height: 6
#| warning: false
#| message: false


g1 =ggplot(data = res, aes(x = algorithm, y = mse, fill = tuned)) +
  geom_boxplot() +
  facet_grid(N~.) + 
  theme_bw() +
  xlab("Algorithm") +
  ylab("MSE")+
  theme(legend.position = c(0.1, 0.15)) +
  theme(strip.background =element_rect(fill="white"))
g1
```


## Learning in neural networks

To understand the internal learning of neural networks, we trained neural networks of two different sizes (3 layers of 50 units and 3 layers of 500 units) on a simple collinear scenario ($Y \sim 1. 0\cdot X_1 + 0.0\cdot X_2+ \epsilon, \epsilon \sim N(0, 0.3)$; X~1~ and X~2~ were collinear (Pearson correlation factor = 0.9)) and calculated the ACE after each batch optimization step. 

We found that the estimates of the botch effect were initially estimated to be around 0 (Fig. S13 A, B), probably due to the initialization of the neural networks, which resembles a shrinkage behavior (weights have to be moved away from 0 step by step in the gradient descent). After this initialization phase, both estimates are within the expected negative log-likelihood surface of OLS (Fig. S13C) and are estimated over the training period to the correct estimates (X~1~ = 1.0 and X~2~ = 0.0). 


```{r}
#| label: fig-Fig_S13
#| warning: false
#| message: false
#| fig-cap: "Learning neural networks. Neural networks were trained on simulated data (1000 observations) with 5 predictors, X~1~ has a linear effect on Y, and X~2~ is collinear with X~1~ (Pearson correlation factor = 0.9). The ACE was computed after each optimization step (i.e., after each batch in stochastic gradient descent) (20 repetitions). Panels A and B show the evolution of the effects for X~1~ and X~2~ (true effects: X~1~ = 1.0 and X~2~ = 0.0). Panel A shows the results for a neural network with 50 units in each of the 3 hidden layers, while Panel B shows the results for a neural network with 500 units in each of the 3 hidden layers. Panel C shows the negative log likelihood surface for the corresponding OLS."
#| fig-width: 10
#| fig-height: 9

res0 = apply(readRDS("results/NN_learning_0.RDS"), 1:2, mean) %>%  as.data.frame()
res50 = apply(readRDS("results/NN_learning_50.RDS"), 1:2, mean) %>%  as.data.frame()
res500 = apply(readRDS("results/NN_learning_500.RDS"), 1:2, mean) %>%  as.data.frame()

a = 
  ggplot(data = res50, aes(V1, V2)) +
    geom_point(color = "lightgrey") +
    geom_line() +
    theme_bw() +
    xlim(-0.2, 1.2) + 
    ylim(-0.2, 1.2) +
    xlab("X1") +
    ylab("X2") + 
    labs(tag = "a") +
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(), 
          panel.background = element_blank())

b = 
  ggplot(data = res500, aes(V1, V2)) +
    geom_point(color = "lightgrey") +
    geom_line() +
    theme_bw() +
    xlim(-0.2, 1.2) + 
    ylim(-0.2, 1.2) +
    labs(tag = "b") +
    xlab("X1") +
    ylab("X2") + 
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(), 
          panel.background = element_blank())

sim = function() simulate(r = 0.9, effs = c(1, 0.0, 0, 0, 0),inter = c(1),n = 1000)
data = sim()
XX = seq(-5, 5, length.out = 50)
DD = expand.grid(XX, XX)

lls = sapply(1:nrow(DD), function(i) sum(dnorm(data[,1], data[,2:3] %*% t(DD[i,]),sd = 0.3, log = TRUE)))
c = 
  ggplot(data.frame(X = DD[,1], Y = DD[,2], Z = lls), aes(X, Y, z= Z)) + 
       geom_contour_filled() +
        theme_bw() + 
    xlab("X1") +
    ylab("X2") + 
    labs(tag = "C", fill='Neg logL') +
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(), 
          panel.background = element_blank())

grid.arrange(a, b, c, nrow = 4, ncol =4, layout_matrix = matrix(c(1, 1, 2, 2, 1, 1, 2, 2, 3, 3, 3, 4, 3, 3, 3, 4), 4, 4, byrow = TRUE))
```


## References